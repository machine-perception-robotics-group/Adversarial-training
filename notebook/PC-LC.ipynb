{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be933234-4b51-41a5-a5a0-9b831b916f96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Probabilistically compact loss with logits constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85eb3db2-6a80-4e98-8a62-4fd714fc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import yaml\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66240c81-1be4-4a34-af22-21a6292e0ff9",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01de849e-a804-4062-aef7-4cfcd5999b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = '0,1,2,3'\n",
    "dataset = 'cifar10'\n",
    "model_type = 'wrn34-10'\n",
    "checkpoint = './checkpoint/pc_with_logits_const_at/%s/%s' % (model_type, dataset)\n",
    "num_classes = 10\n",
    "lr = 0.01\n",
    "batch_size = 256\n",
    "total_epochs = 300\n",
    "xi = 0.995\n",
    "lam = 0.05\n",
    "epsilon = 8/255\n",
    "alpha = 2/255\n",
    "num_repeats = 10\n",
    "warm_up = total_epochs//2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c102405-4d46-45e0-b957-9e7022b7ae2f",
   "metadata": {},
   "source": [
    "## Inner maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee44a0f-0acc-41c3-95a0-e477e167e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_max(model, xent, inputs, targets, epsilon, alpha, num_repeats):\n",
    "    noise = torch.FloatTensor(inputs.shape).uniform_(-epsilon, epsilon).cuda()\n",
    "    x = torch.clamp(inputs + noise, min=0, max=1)\n",
    "    \n",
    "    for _ in range(num_repeats):\n",
    "        x.requires_grad_()\n",
    "        logits = model(x)\n",
    "        loss = xent(logits, targets)\n",
    "        loss.backward()\n",
    "        grads = x.grad.data\n",
    "        x = x.detach() + alpha*torch.sign(grads).detach()\n",
    "        x = torch.min(torch.max(x, inputs-epsilon), inputs+epsilon).clamp(min=0, max=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2591b-4ebf-4714-a3f4-85cdac7f272d",
   "metadata": {},
   "source": [
    "## Training (Outer minimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2276c9-d52b-4544-8448-42817161084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch, model, dataloader, optimizer, num_classes, xi, lam, warm_up, \n",
    "             epsilon=8/255, alpha=2/255, num_repeats=10, use_at=False):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "        \n",
    "    hinge = nn.ReLU()\n",
    "    xent = nn.CrossEntropyLoss()\n",
    "    for idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        batch = inputs.size(0)\n",
    "        \n",
    "        if use_at:\n",
    "            x = inner_max(model, xent, inputs, targets, epsilon, alpha, num_repeats)\n",
    "        else:\n",
    "            x = inputs.clone()\n",
    "        logits = model(x)\n",
    "        \n",
    "        if warm_up < epoch:\n",
    "            classes = torch.arange(num_classes)[None,:].repeat(batch,1).cuda()\n",
    "            labels = targets[:,None].repeat(1,num_classes)\n",
    "            mask = logits.softmax(dim=1).eq(labels)\n",
    "            gt_probs = torch.sum(mask * logits.softmax(dim=1), dim=1, keepdim=True).repeat(1,num_classes)\n",
    "            diff = false_probs + xi - gt_probs\n",
    "            zeros = torch.zeros_like(gt_probs)\n",
    "            pc_loss = (torch.sum(torch.max(zeros, diff))/batch - xi) / (num_classes-1)\n",
    "            #false_probs = logits.softmax(dim=1)[classes!=targets[:,None]].view(batch, logits.size(1)-1)\n",
    "            #gt_probs = logits.softmax(dim=1)[classes==targets[:,None]].unsqueeze(1).repeat(1, num_classes-1)\n",
    "            # (torch.max(zeros, diff).sum() / batch_size - self.margin)  / (self.num_classes - 1)\n",
    "            \n",
    "            true_logits = mask * logits.softmax(dim=1)\n",
    "            gt_mask = -1e3*mask\n",
    "            false_logits = logits - true_logits + gt_mask\n",
    "            \n",
    "            false_logits_max = F.softmax(false_logits, dim=1)\n",
    "            \n",
    "            diff = false_logits_max * (gt_probs - logits)\n",
    "            lc_loss = torch.max(zeros, diff).sum() / batch\n",
    "            #gt_logits = logits[classes == targets[:,None]]\n",
    "            #false_logits = logits[classes != targets[:,None]].view(batch,num_classes-1)\n",
    "            #top2_logits = torch.topk(false_logits, k=2)[0][:,0]\n",
    "            #const = torch.sum(hinge(gt_logits - top2_logits)) / batch\n",
    "            \n",
    "            loss = pc_loss + lam*lc_loss\n",
    "        else:\n",
    "            loss = xent(logits, targets)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        total += batch\n",
    "        total_loss += loss.item()\n",
    "        num_correct = torch.argmax(logits.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "        total_correct += num_correct\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print('Epoch %d [%d/%d] | loss: %.4f (avg: %.4f) | acc: %.4f (avg: %.4f) |'\\\n",
    "                  % (epoch, idx, len(dataloader), loss.item(), total_loss/len(dataloader),\n",
    "                     num_correct/batch, total_correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff1c8d2-8e9c-441c-b471-9eb237eb3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(epoch, model, dataloader, alpha, epsilon, num_repeats):\n",
    "    model.eval()\n",
    "    total_correct_nat = 0\n",
    "    total_correct_adv = 0\n",
    "    \n",
    "    xent = nn.CrossEntropyLoss()\n",
    "    for samples in dataloader:\n",
    "        inputs, targets = samples[0].cuda(), samples[1].cuda()\n",
    "        batch = inputs.size(0)\n",
    "        with torch.enable_grad():\n",
    "            x = inner_max(model, xent, inputs, targets, epsilon, alpha, num_repeats)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            logits_nat = model(inputs)\n",
    "            logits_adv = model(x)\n",
    "        \n",
    "        total_correct_nat += torch.argmax(logits_nat.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "        total_correct_adv += torch.argmax(logits_adv.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "        \n",
    "    print('Validation | acc (nat): %.4f | acc (rob): %.4f |' % (total_correct_nat / len(dataloader.dataset),\n",
    "                                                                total_correct_adv / len(dataloader.dataset)))\n",
    "    return (total_correct_nat / len(dataloader.dataset)), (total_correct_adv / len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "208f000e-cb35-4ad5-93d5-fe47f788b266",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0 [0/192] | loss: 3.1064 (avg: 0.0162) | acc: 0.0000 (avg: 0.0000) |\n",
      "Epoch 0 [100/192] | loss: 2.1563 (avg: 1.2056) | acc: 0.2422 (avg: 0.1538) |\n",
      "Validation | acc (nat): 0.2460 | acc (rob): 0.2000 |\n",
      "Epoch 1 [0/192] | loss: 2.1259 (avg: 0.0111) | acc: 0.2031 (avg: 0.2031) |\n",
      "Epoch 1 [100/192] | loss: 2.1147 (avg: 1.1124) | acc: 0.2070 (avg: 0.2141) |\n",
      "Validation | acc (nat): 0.3030 | acc (rob): 0.2240 |\n",
      "Epoch 2 [0/192] | loss: 2.0152 (avg: 0.0105) | acc: 0.2383 (avg: 0.2383) |\n",
      "Epoch 2 [100/192] | loss: 1.9911 (avg: 1.0537) | acc: 0.2461 (avg: 0.2451) |\n",
      "Validation | acc (nat): 0.3730 | acc (rob): 0.2460 |\n",
      "Epoch 3 [0/192] | loss: 1.9719 (avg: 0.0103) | acc: 0.2383 (avg: 0.2383) |\n",
      "Epoch 3 [100/192] | loss: 1.8483 (avg: 1.0183) | acc: 0.3242 (avg: 0.2747) |\n",
      "Validation | acc (nat): 0.4000 | acc (rob): 0.2780 |\n",
      "Epoch 4 [0/192] | loss: 1.9239 (avg: 0.0100) | acc: 0.2539 (avg: 0.2539) |\n",
      "Epoch 4 [100/192] | loss: 1.8200 (avg: 0.9745) | acc: 0.3516 (avg: 0.3055) |\n",
      "Validation | acc (nat): 0.4710 | acc (rob): 0.3020 |\n",
      "Epoch 5 [0/192] | loss: 1.7692 (avg: 0.0092) | acc: 0.3203 (avg: 0.3203) |\n",
      "Epoch 5 [100/192] | loss: 1.8220 (avg: 0.9336) | acc: 0.2930 (avg: 0.3359) |\n",
      "Validation | acc (nat): 0.5130 | acc (rob): 0.3180 |\n",
      "Epoch 6 [0/192] | loss: 1.8143 (avg: 0.0094) | acc: 0.3008 (avg: 0.3008) |\n",
      "Epoch 6 [100/192] | loss: 1.6040 (avg: 0.8954) | acc: 0.4023 (avg: 0.3587) |\n",
      "Validation | acc (nat): 0.5780 | acc (rob): 0.3540 |\n",
      "Epoch 7 [0/192] | loss: 1.6202 (avg: 0.0084) | acc: 0.3633 (avg: 0.3633) |\n",
      "Epoch 7 [100/192] | loss: 1.5410 (avg: 0.8605) | acc: 0.4180 (avg: 0.3837) |\n",
      "Validation | acc (nat): 0.6140 | acc (rob): 0.3580 |\n",
      "Epoch 8 [0/192] | loss: 1.5846 (avg: 0.0083) | acc: 0.3945 (avg: 0.3945) |\n",
      "Epoch 8 [100/192] | loss: 1.5121 (avg: 0.8311) | acc: 0.4219 (avg: 0.4025) |\n",
      "Validation | acc (nat): 0.6300 | acc (rob): 0.3900 |\n",
      "Epoch 9 [0/192] | loss: 1.5713 (avg: 0.0082) | acc: 0.3789 (avg: 0.3789) |\n",
      "Epoch 9 [100/192] | loss: 1.5328 (avg: 0.8072) | acc: 0.4141 (avg: 0.4216) |\n",
      "Validation | acc (nat): 0.6540 | acc (rob): 0.3980 |\n",
      "Epoch 10 [0/192] | loss: 1.6096 (avg: 0.0084) | acc: 0.3594 (avg: 0.3594) |\n",
      "Epoch 10 [100/192] | loss: 1.4780 (avg: 0.7785) | acc: 0.4531 (avg: 0.4413) |\n",
      "Validation | acc (nat): 0.6580 | acc (rob): 0.4110 |\n",
      "Epoch 11 [0/192] | loss: 1.4777 (avg: 0.0077) | acc: 0.4414 (avg: 0.4414) |\n",
      "Epoch 11 [100/192] | loss: 1.4336 (avg: 0.7607) | acc: 0.4492 (avg: 0.4520) |\n",
      "Validation | acc (nat): 0.6820 | acc (rob): 0.4090 |\n",
      "Epoch 12 [0/192] | loss: 1.6302 (avg: 0.0085) | acc: 0.3789 (avg: 0.3789) |\n",
      "Epoch 12 [100/192] | loss: 1.3274 (avg: 0.7374) | acc: 0.5195 (avg: 0.4685) |\n",
      "Validation | acc (nat): 0.7090 | acc (rob): 0.4260 |\n",
      "Epoch 13 [0/192] | loss: 1.2996 (avg: 0.0068) | acc: 0.4727 (avg: 0.4727) |\n",
      "Epoch 13 [100/192] | loss: 1.3925 (avg: 0.7117) | acc: 0.4883 (avg: 0.4879) |\n",
      "Validation | acc (nat): 0.7080 | acc (rob): 0.4300 |\n",
      "Epoch 14 [0/192] | loss: 1.3285 (avg: 0.0069) | acc: 0.5234 (avg: 0.5234) |\n",
      "Epoch 14 [100/192] | loss: 1.2868 (avg: 0.6991) | acc: 0.4688 (avg: 0.4887) |\n",
      "Validation | acc (nat): 0.7330 | acc (rob): 0.4390 |\n",
      "Epoch 15 [0/192] | loss: 1.3178 (avg: 0.0069) | acc: 0.5234 (avg: 0.5234) |\n",
      "Epoch 15 [100/192] | loss: 1.3125 (avg: 0.6789) | acc: 0.4961 (avg: 0.5039) |\n",
      "Validation | acc (nat): 0.7200 | acc (rob): 0.4380 |\n",
      "Epoch 16 [0/192] | loss: 1.1976 (avg: 0.0062) | acc: 0.5273 (avg: 0.5273) |\n",
      "Epoch 16 [100/192] | loss: 1.3063 (avg: 0.6630) | acc: 0.5039 (avg: 0.5170) |\n",
      "Validation | acc (nat): 0.7510 | acc (rob): 0.4520 |\n",
      "Epoch 17 [0/192] | loss: 1.2428 (avg: 0.0065) | acc: 0.5312 (avg: 0.5312) |\n",
      "Epoch 17 [100/192] | loss: 1.1400 (avg: 0.6461) | acc: 0.5430 (avg: 0.5254) |\n",
      "Validation | acc (nat): 0.7640 | acc (rob): 0.4730 |\n",
      "Epoch 18 [0/192] | loss: 1.1337 (avg: 0.0059) | acc: 0.5625 (avg: 0.5625) |\n",
      "Epoch 18 [100/192] | loss: 1.1089 (avg: 0.6236) | acc: 0.5508 (avg: 0.5398) |\n",
      "Validation | acc (nat): 0.7490 | acc (rob): 0.4550 |\n",
      "Epoch 19 [0/192] | loss: 1.1585 (avg: 0.0060) | acc: 0.5781 (avg: 0.5781) |\n",
      "Epoch 19 [100/192] | loss: 1.1832 (avg: 0.6089) | acc: 0.5430 (avg: 0.5529) |\n",
      "Validation | acc (nat): 0.7740 | acc (rob): 0.4700 |\n",
      "Epoch 20 [0/192] | loss: 1.1035 (avg: 0.0057) | acc: 0.5820 (avg: 0.5820) |\n",
      "Epoch 20 [100/192] | loss: 1.0360 (avg: 0.5937) | acc: 0.5859 (avg: 0.5600) |\n",
      "Validation | acc (nat): 0.7500 | acc (rob): 0.4720 |\n",
      "Epoch 21 [0/192] | loss: 1.1315 (avg: 0.0059) | acc: 0.5469 (avg: 0.5469) |\n",
      "Epoch 21 [100/192] | loss: 1.1362 (avg: 0.5709) | acc: 0.5469 (avg: 0.5752) |\n",
      "Validation | acc (nat): 0.7730 | acc (rob): 0.4610 |\n",
      "Epoch 22 [0/192] | loss: 1.1218 (avg: 0.0058) | acc: 0.5391 (avg: 0.5391) |\n",
      "Epoch 22 [100/192] | loss: 0.9755 (avg: 0.5567) | acc: 0.6445 (avg: 0.5854) |\n",
      "Validation | acc (nat): 0.7680 | acc (rob): 0.4560 |\n",
      "Epoch 23 [0/192] | loss: 1.1374 (avg: 0.0059) | acc: 0.5664 (avg: 0.5664) |\n",
      "Epoch 23 [100/192] | loss: 1.0511 (avg: 0.5396) | acc: 0.5859 (avg: 0.5962) |\n",
      "Validation | acc (nat): 0.7500 | acc (rob): 0.4710 |\n",
      "Epoch 24 [0/192] | loss: 0.9157 (avg: 0.0048) | acc: 0.6602 (avg: 0.6602) |\n",
      "Epoch 24 [100/192] | loss: 0.9059 (avg: 0.5211) | acc: 0.6680 (avg: 0.6056) |\n",
      "Validation | acc (nat): 0.7730 | acc (rob): 0.4700 |\n",
      "Epoch 25 [0/192] | loss: 0.9293 (avg: 0.0048) | acc: 0.6250 (avg: 0.6250) |\n",
      "Epoch 25 [100/192] | loss: 0.9365 (avg: 0.4981) | acc: 0.6289 (avg: 0.6202) |\n",
      "Validation | acc (nat): 0.7840 | acc (rob): 0.4730 |\n",
      "Epoch 26 [0/192] | loss: 0.8035 (avg: 0.0042) | acc: 0.6562 (avg: 0.6562) |\n",
      "Epoch 26 [100/192] | loss: 0.9495 (avg: 0.4810) | acc: 0.5859 (avg: 0.6298) |\n",
      "Validation | acc (nat): 0.7840 | acc (rob): 0.4500 |\n",
      "Epoch 27 [0/192] | loss: 0.9021 (avg: 0.0047) | acc: 0.6211 (avg: 0.6211) |\n",
      "Epoch 27 [100/192] | loss: 0.9805 (avg: 0.4693) | acc: 0.5703 (avg: 0.6352) |\n",
      "Validation | acc (nat): 0.7800 | acc (rob): 0.4920 |\n",
      "Epoch 28 [0/192] | loss: 0.8363 (avg: 0.0044) | acc: 0.6914 (avg: 0.6914) |\n",
      "Epoch 28 [100/192] | loss: 0.7814 (avg: 0.4455) | acc: 0.6602 (avg: 0.6554) |\n",
      "Validation | acc (nat): 0.7760 | acc (rob): 0.4550 |\n",
      "Epoch 29 [0/192] | loss: 0.8248 (avg: 0.0043) | acc: 0.6914 (avg: 0.6914) |\n",
      "Epoch 29 [100/192] | loss: 0.7901 (avg: 0.4315) | acc: 0.6875 (avg: 0.6632) |\n",
      "Validation | acc (nat): 0.7790 | acc (rob): 0.4730 |\n",
      "Epoch 30 [0/192] | loss: 0.7679 (avg: 0.0040) | acc: 0.6875 (avg: 0.6875) |\n",
      "Epoch 30 [100/192] | loss: 0.7857 (avg: 0.4159) | acc: 0.6602 (avg: 0.6745) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4580 |\n",
      "Epoch 31 [0/192] | loss: 0.7459 (avg: 0.0039) | acc: 0.7031 (avg: 0.7031) |\n",
      "Epoch 31 [100/192] | loss: 0.7657 (avg: 0.3995) | acc: 0.6914 (avg: 0.6850) |\n",
      "Validation | acc (nat): 0.7780 | acc (rob): 0.4370 |\n",
      "Epoch 32 [0/192] | loss: 0.6815 (avg: 0.0035) | acc: 0.7148 (avg: 0.7148) |\n",
      "Epoch 32 [100/192] | loss: 0.7998 (avg: 0.3777) | acc: 0.6680 (avg: 0.7002) |\n",
      "Validation | acc (nat): 0.7780 | acc (rob): 0.4400 |\n",
      "Epoch 33 [0/192] | loss: 0.6656 (avg: 0.0035) | acc: 0.7305 (avg: 0.7305) |\n",
      "Epoch 33 [100/192] | loss: 0.7528 (avg: 0.3621) | acc: 0.6914 (avg: 0.7117) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4440 |\n",
      "Epoch 34 [0/192] | loss: 0.6819 (avg: 0.0036) | acc: 0.6914 (avg: 0.6914) |\n",
      "Epoch 34 [100/192] | loss: 0.6221 (avg: 0.3575) | acc: 0.7305 (avg: 0.7158) |\n",
      "Validation | acc (nat): 0.7860 | acc (rob): 0.4430 |\n",
      "Epoch 35 [0/192] | loss: 0.6506 (avg: 0.0034) | acc: 0.7188 (avg: 0.7188) |\n",
      "Epoch 35 [100/192] | loss: 0.5722 (avg: 0.3432) | acc: 0.7539 (avg: 0.7246) |\n",
      "Validation | acc (nat): 0.7810 | acc (rob): 0.4550 |\n",
      "Epoch 36 [0/192] | loss: 0.6868 (avg: 0.0036) | acc: 0.6953 (avg: 0.6953) |\n",
      "Epoch 36 [100/192] | loss: 0.6768 (avg: 0.3205) | acc: 0.6797 (avg: 0.7435) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4390 |\n",
      "Epoch 37 [0/192] | loss: 0.5450 (avg: 0.0028) | acc: 0.7852 (avg: 0.7852) |\n",
      "Epoch 37 [100/192] | loss: 0.6272 (avg: 0.3114) | acc: 0.7383 (avg: 0.7478) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4340 |\n",
      "Epoch 38 [0/192] | loss: 0.5928 (avg: 0.0031) | acc: 0.7500 (avg: 0.7500) |\n",
      "Epoch 38 [100/192] | loss: 0.6321 (avg: 0.3031) | acc: 0.7422 (avg: 0.7581) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4460 |\n",
      "Epoch 39 [0/192] | loss: 0.5625 (avg: 0.0029) | acc: 0.7461 (avg: 0.7461) |\n",
      "Epoch 39 [100/192] | loss: 0.5045 (avg: 0.2857) | acc: 0.7773 (avg: 0.7684) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4320 |\n",
      "Epoch 40 [0/192] | loss: 0.5289 (avg: 0.0028) | acc: 0.7891 (avg: 0.7891) |\n",
      "Epoch 40 [100/192] | loss: 0.4686 (avg: 0.2795) | acc: 0.7930 (avg: 0.7715) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4350 |\n",
      "Epoch 41 [0/192] | loss: 0.4934 (avg: 0.0026) | acc: 0.7930 (avg: 0.7930) |\n",
      "Epoch 41 [100/192] | loss: 0.5788 (avg: 0.2689) | acc: 0.7383 (avg: 0.7826) |\n",
      "Validation | acc (nat): 0.8140 | acc (rob): 0.4450 |\n",
      "Epoch 42 [0/192] | loss: 0.4667 (avg: 0.0024) | acc: 0.8047 (avg: 0.8047) |\n",
      "Epoch 42 [100/192] | loss: 0.4563 (avg: 0.2521) | acc: 0.7695 (avg: 0.7968) |\n",
      "Validation | acc (nat): 0.7880 | acc (rob): 0.4330 |\n",
      "Epoch 43 [0/192] | loss: 0.4634 (avg: 0.0024) | acc: 0.7773 (avg: 0.7773) |\n",
      "Epoch 43 [100/192] | loss: 0.4685 (avg: 0.2476) | acc: 0.7617 (avg: 0.7981) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4460 |\n",
      "Epoch 44 [0/192] | loss: 0.4165 (avg: 0.0022) | acc: 0.8242 (avg: 0.8242) |\n",
      "Epoch 44 [100/192] | loss: 0.5291 (avg: 0.2401) | acc: 0.7812 (avg: 0.8082) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4290 |\n",
      "Epoch 45 [0/192] | loss: 0.4611 (avg: 0.0024) | acc: 0.8086 (avg: 0.8086) |\n",
      "Epoch 45 [100/192] | loss: 0.4595 (avg: 0.2318) | acc: 0.8047 (avg: 0.8115) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4340 |\n",
      "Epoch 46 [0/192] | loss: 0.4384 (avg: 0.0023) | acc: 0.8242 (avg: 0.8242) |\n",
      "Epoch 46 [100/192] | loss: 0.4679 (avg: 0.2246) | acc: 0.7656 (avg: 0.8195) |\n",
      "Validation | acc (nat): 0.7760 | acc (rob): 0.4370 |\n",
      "Epoch 47 [0/192] | loss: 0.4461 (avg: 0.0023) | acc: 0.7891 (avg: 0.7891) |\n",
      "Epoch 47 [100/192] | loss: 0.3703 (avg: 0.2140) | acc: 0.8320 (avg: 0.8235) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4260 |\n",
      "Epoch 48 [0/192] | loss: 0.4014 (avg: 0.0021) | acc: 0.8281 (avg: 0.8281) |\n",
      "Epoch 48 [100/192] | loss: 0.3963 (avg: 0.2065) | acc: 0.8164 (avg: 0.8314) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4270 |\n",
      "Epoch 49 [0/192] | loss: 0.4345 (avg: 0.0023) | acc: 0.7969 (avg: 0.7969) |\n",
      "Epoch 49 [100/192] | loss: 0.3644 (avg: 0.2038) | acc: 0.8086 (avg: 0.8349) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4450 |\n",
      "Epoch 50 [0/192] | loss: 0.3810 (avg: 0.0020) | acc: 0.8477 (avg: 0.8477) |\n",
      "Epoch 50 [100/192] | loss: 0.3624 (avg: 0.1955) | acc: 0.8242 (avg: 0.8410) |\n",
      "Validation | acc (nat): 0.7910 | acc (rob): 0.4260 |\n",
      "Epoch 51 [0/192] | loss: 0.3860 (avg: 0.0020) | acc: 0.8594 (avg: 0.8594) |\n",
      "Epoch 51 [100/192] | loss: 0.3500 (avg: 0.1874) | acc: 0.8555 (avg: 0.8463) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4250 |\n",
      "Epoch 52 [0/192] | loss: 0.2879 (avg: 0.0015) | acc: 0.8906 (avg: 0.8906) |\n",
      "Epoch 52 [100/192] | loss: 0.3713 (avg: 0.1782) | acc: 0.8477 (avg: 0.8555) |\n",
      "Validation | acc (nat): 0.7880 | acc (rob): 0.4270 |\n",
      "Epoch 53 [0/192] | loss: 0.2958 (avg: 0.0015) | acc: 0.8594 (avg: 0.8594) |\n",
      "Epoch 53 [100/192] | loss: 0.3722 (avg: 0.1743) | acc: 0.8125 (avg: 0.8562) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4260 |\n",
      "Epoch 54 [0/192] | loss: 0.3152 (avg: 0.0016) | acc: 0.8555 (avg: 0.8555) |\n",
      "Epoch 54 [100/192] | loss: 0.3111 (avg: 0.1693) | acc: 0.8828 (avg: 0.8629) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4100 |\n",
      "Epoch 55 [0/192] | loss: 0.2738 (avg: 0.0014) | acc: 0.8867 (avg: 0.8867) |\n",
      "Epoch 55 [100/192] | loss: 0.3677 (avg: 0.1714) | acc: 0.8398 (avg: 0.8620) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4380 |\n",
      "Epoch 56 [0/192] | loss: 0.3089 (avg: 0.0016) | acc: 0.8711 (avg: 0.8711) |\n",
      "Epoch 56 [100/192] | loss: 0.2996 (avg: 0.1628) | acc: 0.8516 (avg: 0.8675) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4040 |\n",
      "Epoch 57 [0/192] | loss: 0.2583 (avg: 0.0013) | acc: 0.9102 (avg: 0.9102) |\n",
      "Epoch 57 [100/192] | loss: 0.2693 (avg: 0.1555) | acc: 0.8789 (avg: 0.8741) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4030 |\n",
      "Epoch 58 [0/192] | loss: 0.2906 (avg: 0.0015) | acc: 0.8672 (avg: 0.8672) |\n",
      "Epoch 58 [100/192] | loss: 0.2708 (avg: 0.1552) | acc: 0.8828 (avg: 0.8730) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4310 |\n",
      "Epoch 59 [0/192] | loss: 0.2487 (avg: 0.0013) | acc: 0.8906 (avg: 0.8906) |\n",
      "Epoch 59 [100/192] | loss: 0.2752 (avg: 0.1537) | acc: 0.8711 (avg: 0.8767) |\n",
      "Validation | acc (nat): 0.7910 | acc (rob): 0.4130 |\n",
      "Epoch 60 [0/192] | loss: 0.3045 (avg: 0.0016) | acc: 0.8594 (avg: 0.8594) |\n",
      "Epoch 60 [100/192] | loss: 0.3016 (avg: 0.1473) | acc: 0.8789 (avg: 0.8793) |\n",
      "Validation | acc (nat): 0.8100 | acc (rob): 0.4170 |\n",
      "Epoch 61 [0/192] | loss: 0.2378 (avg: 0.0012) | acc: 0.8906 (avg: 0.8906) |\n",
      "Epoch 61 [100/192] | loss: 0.2879 (avg: 0.1404) | acc: 0.8945 (avg: 0.8888) |\n",
      "Validation | acc (nat): 0.7930 | acc (rob): 0.4210 |\n",
      "Epoch 62 [0/192] | loss: 0.2300 (avg: 0.0012) | acc: 0.8945 (avg: 0.8945) |\n",
      "Epoch 62 [100/192] | loss: 0.2429 (avg: 0.1366) | acc: 0.8789 (avg: 0.8887) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4000 |\n",
      "Epoch 63 [0/192] | loss: 0.2491 (avg: 0.0013) | acc: 0.8984 (avg: 0.8984) |\n",
      "Epoch 63 [100/192] | loss: 0.3118 (avg: 0.1373) | acc: 0.8789 (avg: 0.8897) |\n",
      "Validation | acc (nat): 0.7810 | acc (rob): 0.4240 |\n",
      "Epoch 64 [0/192] | loss: 0.2068 (avg: 0.0011) | acc: 0.9180 (avg: 0.9180) |\n",
      "Epoch 64 [100/192] | loss: 0.2135 (avg: 0.1357) | acc: 0.9258 (avg: 0.8903) |\n",
      "Validation | acc (nat): 0.7880 | acc (rob): 0.4240 |\n",
      "Epoch 65 [0/192] | loss: 0.2475 (avg: 0.0013) | acc: 0.8828 (avg: 0.8828) |\n",
      "Epoch 65 [100/192] | loss: 0.2507 (avg: 0.1307) | acc: 0.8828 (avg: 0.8930) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4130 |\n",
      "Epoch 66 [0/192] | loss: 0.2099 (avg: 0.0011) | acc: 0.9141 (avg: 0.9141) |\n",
      "Epoch 66 [100/192] | loss: 0.2549 (avg: 0.1288) | acc: 0.8672 (avg: 0.8952) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4120 |\n",
      "Epoch 67 [0/192] | loss: 0.2393 (avg: 0.0012) | acc: 0.9102 (avg: 0.9102) |\n",
      "Epoch 67 [100/192] | loss: 0.2041 (avg: 0.1229) | acc: 0.9219 (avg: 0.9016) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4120 |\n",
      "Epoch 68 [0/192] | loss: 0.2025 (avg: 0.0011) | acc: 0.9141 (avg: 0.9141) |\n",
      "Epoch 68 [100/192] | loss: 0.3225 (avg: 0.1206) | acc: 0.8438 (avg: 0.9026) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4250 |\n",
      "Epoch 69 [0/192] | loss: 0.2120 (avg: 0.0011) | acc: 0.9141 (avg: 0.9141) |\n",
      "Epoch 69 [100/192] | loss: 0.2295 (avg: 0.1156) | acc: 0.8945 (avg: 0.9066) |\n",
      "Validation | acc (nat): 0.8150 | acc (rob): 0.3870 |\n",
      "Epoch 70 [0/192] | loss: 0.2049 (avg: 0.0011) | acc: 0.9219 (avg: 0.9219) |\n",
      "Epoch 70 [100/192] | loss: 0.1985 (avg: 0.1193) | acc: 0.9297 (avg: 0.9064) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4150 |\n",
      "Epoch 71 [0/192] | loss: 0.2502 (avg: 0.0013) | acc: 0.8945 (avg: 0.8945) |\n",
      "Epoch 71 [100/192] | loss: 0.2507 (avg: 0.1135) | acc: 0.8789 (avg: 0.9086) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4000 |\n",
      "Epoch 72 [0/192] | loss: 0.2175 (avg: 0.0011) | acc: 0.9102 (avg: 0.9102) |\n",
      "Epoch 72 [100/192] | loss: 0.1864 (avg: 0.1104) | acc: 0.9219 (avg: 0.9110) |\n",
      "Validation | acc (nat): 0.7910 | acc (rob): 0.4100 |\n",
      "Epoch 73 [0/192] | loss: 0.2167 (avg: 0.0011) | acc: 0.9180 (avg: 0.9180) |\n",
      "Epoch 73 [100/192] | loss: 0.2507 (avg: 0.1065) | acc: 0.8789 (avg: 0.9148) |\n",
      "Validation | acc (nat): 0.7820 | acc (rob): 0.4180 |\n",
      "Epoch 74 [0/192] | loss: 0.1700 (avg: 0.0009) | acc: 0.9258 (avg: 0.9258) |\n",
      "Epoch 74 [100/192] | loss: 0.1504 (avg: 0.1079) | acc: 0.9531 (avg: 0.9139) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4080 |\n",
      "Epoch 75 [0/192] | loss: 0.1797 (avg: 0.0009) | acc: 0.9336 (avg: 0.9336) |\n",
      "Epoch 75 [100/192] | loss: 0.1746 (avg: 0.1069) | acc: 0.9180 (avg: 0.9146) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4270 |\n",
      "Epoch 76 [0/192] | loss: 0.1749 (avg: 0.0009) | acc: 0.9219 (avg: 0.9219) |\n",
      "Epoch 76 [100/192] | loss: 0.1717 (avg: 0.1025) | acc: 0.9258 (avg: 0.9184) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4170 |\n",
      "Epoch 77 [0/192] | loss: 0.1840 (avg: 0.0010) | acc: 0.9336 (avg: 0.9336) |\n",
      "Epoch 77 [100/192] | loss: 0.2031 (avg: 0.1023) | acc: 0.9180 (avg: 0.9198) |\n",
      "Validation | acc (nat): 0.8100 | acc (rob): 0.4070 |\n",
      "Epoch 78 [0/192] | loss: 0.1847 (avg: 0.0010) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 78 [100/192] | loss: 0.1851 (avg: 0.0962) | acc: 0.9258 (avg: 0.9237) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4040 |\n",
      "Epoch 79 [0/192] | loss: 0.1958 (avg: 0.0010) | acc: 0.9141 (avg: 0.9141) |\n",
      "Epoch 79 [100/192] | loss: 0.1908 (avg: 0.0971) | acc: 0.9180 (avg: 0.9220) |\n",
      "Validation | acc (nat): 0.7890 | acc (rob): 0.4200 |\n",
      "Epoch 80 [0/192] | loss: 0.1890 (avg: 0.0010) | acc: 0.9023 (avg: 0.9023) |\n",
      "Epoch 80 [100/192] | loss: 0.2498 (avg: 0.0945) | acc: 0.9102 (avg: 0.9256) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4170 |\n",
      "Epoch 81 [0/192] | loss: 0.2033 (avg: 0.0011) | acc: 0.9219 (avg: 0.9219) |\n",
      "Epoch 81 [100/192] | loss: 0.1818 (avg: 0.0940) | acc: 0.9219 (avg: 0.9258) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4020 |\n",
      "Epoch 82 [0/192] | loss: 0.1568 (avg: 0.0008) | acc: 0.9414 (avg: 0.9414) |\n",
      "Epoch 82 [100/192] | loss: 0.1971 (avg: 0.0930) | acc: 0.8867 (avg: 0.9262) |\n",
      "Validation | acc (nat): 0.7810 | acc (rob): 0.4150 |\n",
      "Epoch 83 [0/192] | loss: 0.1588 (avg: 0.0008) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 83 [100/192] | loss: 0.1888 (avg: 0.0891) | acc: 0.9219 (avg: 0.9291) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4090 |\n",
      "Epoch 84 [0/192] | loss: 0.1493 (avg: 0.0008) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 84 [100/192] | loss: 0.1608 (avg: 0.0922) | acc: 0.9258 (avg: 0.9272) |\n",
      "Validation | acc (nat): 0.7840 | acc (rob): 0.4160 |\n",
      "Epoch 85 [0/192] | loss: 0.1198 (avg: 0.0006) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 85 [100/192] | loss: 0.1364 (avg: 0.0895) | acc: 0.9375 (avg: 0.9299) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4100 |\n",
      "Epoch 86 [0/192] | loss: 0.1405 (avg: 0.0007) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 86 [100/192] | loss: 0.1855 (avg: 0.0854) | acc: 0.9062 (avg: 0.9339) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4200 |\n",
      "Epoch 87 [0/192] | loss: 0.1731 (avg: 0.0009) | acc: 0.9336 (avg: 0.9336) |\n",
      "Epoch 87 [100/192] | loss: 0.1579 (avg: 0.0873) | acc: 0.9414 (avg: 0.9320) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.3910 |\n",
      "Epoch 88 [0/192] | loss: 0.1466 (avg: 0.0008) | acc: 0.9414 (avg: 0.9414) |\n",
      "Epoch 88 [100/192] | loss: 0.1544 (avg: 0.0799) | acc: 0.9297 (avg: 0.9384) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4190 |\n",
      "Epoch 89 [0/192] | loss: 0.1549 (avg: 0.0008) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 89 [100/192] | loss: 0.1608 (avg: 0.0815) | acc: 0.9414 (avg: 0.9364) |\n",
      "Validation | acc (nat): 0.8160 | acc (rob): 0.4120 |\n",
      "Epoch 90 [0/192] | loss: 0.1677 (avg: 0.0009) | acc: 0.9141 (avg: 0.9141) |\n",
      "Epoch 90 [100/192] | loss: 0.1438 (avg: 0.0845) | acc: 0.9375 (avg: 0.9356) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4160 |\n",
      "Epoch 91 [0/192] | loss: 0.1224 (avg: 0.0006) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 91 [100/192] | loss: 0.1497 (avg: 0.0817) | acc: 0.9375 (avg: 0.9367) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4210 |\n",
      "Epoch 92 [0/192] | loss: 0.1656 (avg: 0.0009) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 92 [100/192] | loss: 0.1345 (avg: 0.0801) | acc: 0.9570 (avg: 0.9373) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4110 |\n",
      "Epoch 93 [0/192] | loss: 0.1578 (avg: 0.0008) | acc: 0.9414 (avg: 0.9414) |\n",
      "Epoch 93 [100/192] | loss: 0.1543 (avg: 0.0785) | acc: 0.9258 (avg: 0.9399) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4100 |\n",
      "Epoch 94 [0/192] | loss: 0.1346 (avg: 0.0007) | acc: 0.9453 (avg: 0.9453) |\n",
      "Epoch 94 [100/192] | loss: 0.1148 (avg: 0.0772) | acc: 0.9688 (avg: 0.9417) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4200 |\n",
      "Epoch 95 [0/192] | loss: 0.1358 (avg: 0.0007) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 95 [100/192] | loss: 0.1430 (avg: 0.0740) | acc: 0.9336 (avg: 0.9424) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4240 |\n",
      "Epoch 96 [0/192] | loss: 0.1422 (avg: 0.0007) | acc: 0.9492 (avg: 0.9492) |\n",
      "Epoch 96 [100/192] | loss: 0.1699 (avg: 0.0738) | acc: 0.9258 (avg: 0.9431) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4420 |\n",
      "Epoch 97 [0/192] | loss: 0.1367 (avg: 0.0007) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 97 [100/192] | loss: 0.1762 (avg: 0.0743) | acc: 0.9141 (avg: 0.9425) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4260 |\n",
      "Epoch 98 [0/192] | loss: 0.1394 (avg: 0.0007) | acc: 0.9336 (avg: 0.9336) |\n",
      "Epoch 98 [100/192] | loss: 0.1112 (avg: 0.0732) | acc: 0.9453 (avg: 0.9441) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4270 |\n",
      "Epoch 99 [0/192] | loss: 0.1508 (avg: 0.0008) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 99 [100/192] | loss: 0.1228 (avg: 0.0740) | acc: 0.9375 (avg: 0.9436) |\n",
      "Validation | acc (nat): 0.8180 | acc (rob): 0.4150 |\n",
      "Epoch 100 [0/192] | loss: 0.1129 (avg: 0.0006) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 100 [100/192] | loss: 0.1348 (avg: 0.0704) | acc: 0.9531 (avg: 0.9457) |\n",
      "Validation | acc (nat): 0.7890 | acc (rob): 0.4270 |\n",
      "Epoch 101 [0/192] | loss: 0.1523 (avg: 0.0008) | acc: 0.9453 (avg: 0.9453) |\n",
      "Epoch 101 [100/192] | loss: 0.1615 (avg: 0.0703) | acc: 0.9258 (avg: 0.9459) |\n",
      "Validation | acc (nat): 0.8170 | acc (rob): 0.4180 |\n",
      "Epoch 102 [0/192] | loss: 0.1145 (avg: 0.0006) | acc: 0.9453 (avg: 0.9453) |\n",
      "Epoch 102 [100/192] | loss: 0.1423 (avg: 0.0663) | acc: 0.9336 (avg: 0.9494) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4280 |\n",
      "Epoch 103 [0/192] | loss: 0.1060 (avg: 0.0006) | acc: 0.9492 (avg: 0.9492) |\n",
      "Epoch 103 [100/192] | loss: 0.1507 (avg: 0.0693) | acc: 0.9453 (avg: 0.9474) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4140 |\n",
      "Epoch 104 [0/192] | loss: 0.1628 (avg: 0.0008) | acc: 0.9258 (avg: 0.9258) |\n",
      "Epoch 104 [100/192] | loss: 0.1096 (avg: 0.0642) | acc: 0.9648 (avg: 0.9512) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4120 |\n",
      "Epoch 105 [0/192] | loss: 0.0985 (avg: 0.0005) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 105 [100/192] | loss: 0.1149 (avg: 0.0706) | acc: 0.9492 (avg: 0.9462) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4230 |\n",
      "Epoch 106 [0/192] | loss: 0.0889 (avg: 0.0005) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 106 [100/192] | loss: 0.1106 (avg: 0.0662) | acc: 0.9570 (avg: 0.9497) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4140 |\n",
      "Epoch 107 [0/192] | loss: 0.1226 (avg: 0.0006) | acc: 0.9375 (avg: 0.9375) |\n",
      "Epoch 107 [100/192] | loss: 0.1164 (avg: 0.0634) | acc: 0.9609 (avg: 0.9511) |\n",
      "Validation | acc (nat): 0.8130 | acc (rob): 0.4340 |\n",
      "Epoch 108 [0/192] | loss: 0.1020 (avg: 0.0005) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 108 [100/192] | loss: 0.1255 (avg: 0.0625) | acc: 0.9570 (avg: 0.9519) |\n",
      "Validation | acc (nat): 0.8150 | acc (rob): 0.4070 |\n",
      "Epoch 109 [0/192] | loss: 0.1488 (avg: 0.0008) | acc: 0.9297 (avg: 0.9297) |\n",
      "Epoch 109 [100/192] | loss: 0.1046 (avg: 0.0621) | acc: 0.9570 (avg: 0.9541) |\n",
      "Validation | acc (nat): 0.7870 | acc (rob): 0.4270 |\n",
      "Epoch 110 [0/192] | loss: 0.1324 (avg: 0.0007) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 110 [100/192] | loss: 0.1355 (avg: 0.0610) | acc: 0.9531 (avg: 0.9546) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4220 |\n",
      "Epoch 111 [0/192] | loss: 0.0839 (avg: 0.0004) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 111 [100/192] | loss: 0.1506 (avg: 0.0650) | acc: 0.9258 (avg: 0.9503) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4140 |\n",
      "Epoch 112 [0/192] | loss: 0.1247 (avg: 0.0006) | acc: 0.9492 (avg: 0.9492) |\n",
      "Epoch 112 [100/192] | loss: 0.0844 (avg: 0.0609) | acc: 0.9805 (avg: 0.9562) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4140 |\n",
      "Epoch 113 [0/192] | loss: 0.0909 (avg: 0.0005) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 113 [100/192] | loss: 0.1096 (avg: 0.0597) | acc: 0.9609 (avg: 0.9570) |\n",
      "Validation | acc (nat): 0.7880 | acc (rob): 0.4010 |\n",
      "Epoch 114 [0/192] | loss: 0.0919 (avg: 0.0005) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 114 [100/192] | loss: 0.1059 (avg: 0.0591) | acc: 0.9648 (avg: 0.9559) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4100 |\n",
      "Epoch 115 [0/192] | loss: 0.0851 (avg: 0.0004) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 115 [100/192] | loss: 0.0984 (avg: 0.0590) | acc: 0.9648 (avg: 0.9564) |\n",
      "Validation | acc (nat): 0.8120 | acc (rob): 0.4140 |\n",
      "Epoch 116 [0/192] | loss: 0.0852 (avg: 0.0004) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 116 [100/192] | loss: 0.1140 (avg: 0.0579) | acc: 0.9570 (avg: 0.9556) |\n",
      "Validation | acc (nat): 0.8100 | acc (rob): 0.4080 |\n",
      "Epoch 117 [0/192] | loss: 0.1374 (avg: 0.0007) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 117 [100/192] | loss: 0.1332 (avg: 0.0594) | acc: 0.9453 (avg: 0.9558) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4140 |\n",
      "Epoch 118 [0/192] | loss: 0.1120 (avg: 0.0006) | acc: 0.9492 (avg: 0.9492) |\n",
      "Epoch 118 [100/192] | loss: 0.1328 (avg: 0.0581) | acc: 0.9531 (avg: 0.9565) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4310 |\n",
      "Epoch 119 [0/192] | loss: 0.1227 (avg: 0.0006) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 119 [100/192] | loss: 0.1456 (avg: 0.0580) | acc: 0.9336 (avg: 0.9566) |\n",
      "Validation | acc (nat): 0.8210 | acc (rob): 0.4070 |\n",
      "Epoch 120 [0/192] | loss: 0.0899 (avg: 0.0005) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 120 [100/192] | loss: 0.1033 (avg: 0.0558) | acc: 0.9648 (avg: 0.9598) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4140 |\n",
      "Epoch 121 [0/192] | loss: 0.0660 (avg: 0.0003) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 121 [100/192] | loss: 0.1061 (avg: 0.0562) | acc: 0.9531 (avg: 0.9590) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4230 |\n",
      "Epoch 122 [0/192] | loss: 0.0996 (avg: 0.0005) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 122 [100/192] | loss: 0.0833 (avg: 0.0595) | acc: 0.9688 (avg: 0.9559) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4270 |\n",
      "Epoch 123 [0/192] | loss: 0.0989 (avg: 0.0005) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 123 [100/192] | loss: 0.1361 (avg: 0.0564) | acc: 0.9531 (avg: 0.9581) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4110 |\n",
      "Epoch 124 [0/192] | loss: 0.0995 (avg: 0.0005) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 124 [100/192] | loss: 0.1027 (avg: 0.0516) | acc: 0.9766 (avg: 0.9627) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4030 |\n",
      "Epoch 125 [0/192] | loss: 0.0667 (avg: 0.0003) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 125 [100/192] | loss: 0.1067 (avg: 0.0534) | acc: 0.9570 (avg: 0.9616) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4350 |\n",
      "Epoch 126 [0/192] | loss: 0.0822 (avg: 0.0004) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 126 [100/192] | loss: 0.1094 (avg: 0.0554) | acc: 0.9492 (avg: 0.9592) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4210 |\n",
      "Epoch 127 [0/192] | loss: 0.0870 (avg: 0.0005) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 127 [100/192] | loss: 0.0669 (avg: 0.0522) | acc: 0.9727 (avg: 0.9622) |\n",
      "Validation | acc (nat): 0.8130 | acc (rob): 0.4200 |\n",
      "Epoch 128 [0/192] | loss: 0.0522 (avg: 0.0003) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 128 [100/192] | loss: 0.1167 (avg: 0.0507) | acc: 0.9609 (avg: 0.9622) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4240 |\n",
      "Epoch 129 [0/192] | loss: 0.1061 (avg: 0.0006) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 129 [100/192] | loss: 0.1088 (avg: 0.0530) | acc: 0.9609 (avg: 0.9617) |\n",
      "Validation | acc (nat): 0.8140 | acc (rob): 0.4110 |\n",
      "Epoch 130 [0/192] | loss: 0.0790 (avg: 0.0004) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 130 [100/192] | loss: 0.0722 (avg: 0.0498) | acc: 0.9688 (avg: 0.9643) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4230 |\n",
      "Epoch 131 [0/192] | loss: 0.0656 (avg: 0.0003) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 131 [100/192] | loss: 0.0965 (avg: 0.0504) | acc: 0.9609 (avg: 0.9638) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4320 |\n",
      "Epoch 132 [0/192] | loss: 0.0998 (avg: 0.0005) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 132 [100/192] | loss: 0.1134 (avg: 0.0512) | acc: 0.9609 (avg: 0.9619) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4260 |\n",
      "Epoch 133 [0/192] | loss: 0.1044 (avg: 0.0005) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 133 [100/192] | loss: 0.0824 (avg: 0.0514) | acc: 0.9609 (avg: 0.9634) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4230 |\n",
      "Epoch 134 [0/192] | loss: 0.0814 (avg: 0.0004) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 134 [100/192] | loss: 0.0897 (avg: 0.0503) | acc: 0.9648 (avg: 0.9624) |\n",
      "Validation | acc (nat): 0.8100 | acc (rob): 0.4170 |\n",
      "Epoch 135 [0/192] | loss: 0.1017 (avg: 0.0005) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 135 [100/192] | loss: 0.0694 (avg: 0.0475) | acc: 0.9805 (avg: 0.9655) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4310 |\n",
      "Epoch 136 [0/192] | loss: 0.0713 (avg: 0.0004) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 136 [100/192] | loss: 0.1328 (avg: 0.0482) | acc: 0.9336 (avg: 0.9640) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4260 |\n",
      "Epoch 137 [0/192] | loss: 0.0904 (avg: 0.0005) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 137 [100/192] | loss: 0.0786 (avg: 0.0469) | acc: 0.9688 (avg: 0.9662) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4150 |\n",
      "Epoch 138 [0/192] | loss: 0.0994 (avg: 0.0005) | acc: 0.9453 (avg: 0.9453) |\n",
      "Epoch 138 [100/192] | loss: 0.0761 (avg: 0.0457) | acc: 0.9844 (avg: 0.9666) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4310 |\n",
      "Epoch 139 [0/192] | loss: 0.0775 (avg: 0.0004) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 139 [100/192] | loss: 0.1148 (avg: 0.0462) | acc: 0.9492 (avg: 0.9676) |\n",
      "Validation | acc (nat): 0.7890 | acc (rob): 0.4170 |\n",
      "Epoch 140 [0/192] | loss: 0.0758 (avg: 0.0004) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 140 [100/192] | loss: 0.0656 (avg: 0.0482) | acc: 0.9727 (avg: 0.9656) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4200 |\n",
      "Epoch 141 [0/192] | loss: 0.0871 (avg: 0.0005) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 141 [100/192] | loss: 0.0863 (avg: 0.0459) | acc: 0.9648 (avg: 0.9672) |\n",
      "Validation | acc (nat): 0.8140 | acc (rob): 0.4200 |\n",
      "Epoch 142 [0/192] | loss: 0.1150 (avg: 0.0006) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 142 [100/192] | loss: 0.0668 (avg: 0.0474) | acc: 0.9727 (avg: 0.9662) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4310 |\n",
      "Epoch 143 [0/192] | loss: 0.0889 (avg: 0.0005) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 143 [100/192] | loss: 0.0812 (avg: 0.0472) | acc: 0.9688 (avg: 0.9657) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4220 |\n",
      "Epoch 144 [0/192] | loss: 0.1070 (avg: 0.0006) | acc: 0.9531 (avg: 0.9531) |\n",
      "Epoch 144 [100/192] | loss: 0.1021 (avg: 0.0438) | acc: 0.9609 (avg: 0.9696) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4220 |\n",
      "Epoch 145 [0/192] | loss: 0.0924 (avg: 0.0005) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 145 [100/192] | loss: 0.0837 (avg: 0.0444) | acc: 0.9727 (avg: 0.9684) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4210 |\n",
      "Epoch 146 [0/192] | loss: 0.0870 (avg: 0.0005) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 146 [100/192] | loss: 0.0988 (avg: 0.0469) | acc: 0.9688 (avg: 0.9662) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4240 |\n",
      "Epoch 147 [0/192] | loss: 0.0864 (avg: 0.0005) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 147 [100/192] | loss: 0.0968 (avg: 0.0455) | acc: 0.9727 (avg: 0.9676) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4330 |\n",
      "Epoch 148 [0/192] | loss: 0.0772 (avg: 0.0004) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 148 [100/192] | loss: 0.0755 (avg: 0.0457) | acc: 0.9688 (avg: 0.9673) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4270 |\n",
      "Epoch 149 [0/192] | loss: 0.0919 (avg: 0.0005) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 149 [100/192] | loss: 0.1264 (avg: 0.0438) | acc: 0.9688 (avg: 0.9678) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4140 |\n",
      "Epoch 150 [0/192] | loss: 0.0848 (avg: 0.0004) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 150 [100/192] | loss: 0.0916 (avg: 0.0427) | acc: 0.9648 (avg: 0.9700) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4280 |\n",
      "Epoch 151 [0/192] | loss: 0.9410 (avg: 0.0049) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 151 [100/192] | loss: 2.2861 (avg: 1.0333) | acc: 0.7930 (avg: 0.8439) |\n",
      "Validation | acc (nat): 0.7730 | acc (rob): 0.3830 |\n",
      "Epoch 152 [0/192] | loss: 1.6324 (avg: 0.0085) | acc: 0.8828 (avg: 0.8828) |\n",
      "Epoch 152 [100/192] | loss: 1.7231 (avg: 0.7787) | acc: 0.8477 (avg: 0.8980) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4200 |\n",
      "Epoch 153 [0/192] | loss: 1.0813 (avg: 0.0056) | acc: 0.9336 (avg: 0.9336) |\n",
      "Epoch 153 [100/192] | loss: 1.1524 (avg: 0.5896) | acc: 0.9414 (avg: 0.9373) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4130 |\n",
      "Epoch 154 [0/192] | loss: 1.0194 (avg: 0.0053) | acc: 0.9570 (avg: 0.9570) |\n",
      "Epoch 154 [100/192] | loss: 1.0377 (avg: 0.5137) | acc: 0.9375 (avg: 0.9515) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4350 |\n",
      "Epoch 155 [0/192] | loss: 0.7816 (avg: 0.0041) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 155 [100/192] | loss: 0.9607 (avg: 0.4634) | acc: 0.9609 (avg: 0.9597) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4340 |\n",
      "Epoch 156 [0/192] | loss: 0.9382 (avg: 0.0049) | acc: 0.9453 (avg: 0.9453) |\n",
      "Epoch 156 [100/192] | loss: 0.9198 (avg: 0.4232) | acc: 0.9531 (avg: 0.9665) |\n",
      "Validation | acc (nat): 0.7900 | acc (rob): 0.4330 |\n",
      "Epoch 157 [0/192] | loss: 0.7626 (avg: 0.0040) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 157 [100/192] | loss: 0.8077 (avg: 0.3954) | acc: 0.9648 (avg: 0.9704) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4370 |\n",
      "Epoch 158 [0/192] | loss: 0.8245 (avg: 0.0043) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 158 [100/192] | loss: 0.6536 (avg: 0.3854) | acc: 0.9727 (avg: 0.9710) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4310 |\n",
      "Epoch 159 [0/192] | loss: 0.6630 (avg: 0.0035) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 159 [100/192] | loss: 0.7500 (avg: 0.3681) | acc: 0.9805 (avg: 0.9742) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4510 |\n",
      "Epoch 160 [0/192] | loss: 0.5866 (avg: 0.0031) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 160 [100/192] | loss: 0.6617 (avg: 0.3640) | acc: 0.9805 (avg: 0.9733) |\n",
      "Validation | acc (nat): 0.8120 | acc (rob): 0.4360 |\n",
      "Epoch 161 [0/192] | loss: 0.6253 (avg: 0.0033) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 161 [100/192] | loss: 0.5878 (avg: 0.3416) | acc: 0.9844 (avg: 0.9766) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4270 |\n",
      "Epoch 162 [0/192] | loss: 0.5887 (avg: 0.0031) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 162 [100/192] | loss: 0.6270 (avg: 0.3347) | acc: 0.9805 (avg: 0.9781) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4260 |\n",
      "Epoch 163 [0/192] | loss: 0.6281 (avg: 0.0033) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 163 [100/192] | loss: 0.5768 (avg: 0.3359) | acc: 0.9844 (avg: 0.9775) |\n",
      "Validation | acc (nat): 0.8040 | acc (rob): 0.4440 |\n",
      "Epoch 164 [0/192] | loss: 0.5082 (avg: 0.0026) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 164 [100/192] | loss: 0.7074 (avg: 0.3489) | acc: 0.9688 (avg: 0.9739) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4390 |\n",
      "Epoch 165 [0/192] | loss: 0.6650 (avg: 0.0035) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 165 [100/192] | loss: 0.5818 (avg: 0.3308) | acc: 0.9805 (avg: 0.9776) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4470 |\n",
      "Epoch 166 [0/192] | loss: 0.5717 (avg: 0.0030) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 166 [100/192] | loss: 0.6997 (avg: 0.3309) | acc: 0.9727 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4390 |\n",
      "Epoch 167 [0/192] | loss: 0.5440 (avg: 0.0028) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 167 [100/192] | loss: 0.6009 (avg: 0.3160) | acc: 0.9766 (avg: 0.9783) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4430 |\n",
      "Epoch 168 [0/192] | loss: 0.5392 (avg: 0.0028) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 168 [100/192] | loss: 0.6743 (avg: 0.3184) | acc: 0.9727 (avg: 0.9780) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4390 |\n",
      "Epoch 169 [0/192] | loss: 0.5009 (avg: 0.0026) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 169 [100/192] | loss: 0.6050 (avg: 0.3065) | acc: 0.9766 (avg: 0.9797) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4380 |\n",
      "Epoch 170 [0/192] | loss: 0.5263 (avg: 0.0027) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 170 [100/192] | loss: 0.7043 (avg: 0.3119) | acc: 0.9609 (avg: 0.9782) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4440 |\n",
      "Epoch 171 [0/192] | loss: 0.4916 (avg: 0.0026) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 171 [100/192] | loss: 0.5994 (avg: 0.3120) | acc: 0.9766 (avg: 0.9775) |\n",
      "Validation | acc (nat): 0.8220 | acc (rob): 0.4560 |\n",
      "Epoch 172 [0/192] | loss: 0.6149 (avg: 0.0032) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 172 [100/192] | loss: 0.5834 (avg: 0.3186) | acc: 0.9805 (avg: 0.9766) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4520 |\n",
      "Epoch 173 [0/192] | loss: 0.5952 (avg: 0.0031) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 173 [100/192] | loss: 0.4865 (avg: 0.3133) | acc: 0.9844 (avg: 0.9767) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4440 |\n",
      "Epoch 174 [0/192] | loss: 0.6523 (avg: 0.0034) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 174 [100/192] | loss: 0.5093 (avg: 0.3130) | acc: 0.9844 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4400 |\n",
      "Epoch 175 [0/192] | loss: 0.6763 (avg: 0.0035) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 175 [100/192] | loss: 0.6805 (avg: 0.3246) | acc: 0.9688 (avg: 0.9737) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4360 |\n",
      "Epoch 176 [0/192] | loss: 0.6244 (avg: 0.0033) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 176 [100/192] | loss: 0.6703 (avg: 0.2995) | acc: 0.9688 (avg: 0.9786) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4530 |\n",
      "Epoch 177 [0/192] | loss: 0.5715 (avg: 0.0030) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 177 [100/192] | loss: 0.5588 (avg: 0.3076) | acc: 0.9766 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.8080 | acc (rob): 0.4480 |\n",
      "Epoch 178 [0/192] | loss: 0.5553 (avg: 0.0029) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 178 [100/192] | loss: 0.5605 (avg: 0.3089) | acc: 0.9805 (avg: 0.9763) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4440 |\n",
      "Epoch 179 [0/192] | loss: 0.5686 (avg: 0.0030) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 179 [100/192] | loss: 0.6008 (avg: 0.3197) | acc: 0.9727 (avg: 0.9735) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4570 |\n",
      "Epoch 180 [0/192] | loss: 0.5678 (avg: 0.0030) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 180 [100/192] | loss: 0.5972 (avg: 0.3157) | acc: 0.9727 (avg: 0.9745) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4590 |\n",
      "Epoch 181 [0/192] | loss: 0.5349 (avg: 0.0028) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 181 [100/192] | loss: 0.5616 (avg: 0.3059) | acc: 0.9766 (avg: 0.9763) |\n",
      "Validation | acc (nat): 0.7840 | acc (rob): 0.4360 |\n",
      "Epoch 182 [0/192] | loss: 0.6691 (avg: 0.0035) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 182 [100/192] | loss: 0.6752 (avg: 0.3041) | acc: 0.9688 (avg: 0.9763) |\n",
      "Validation | acc (nat): 0.8040 | acc (rob): 0.4490 |\n",
      "Epoch 183 [0/192] | loss: 0.6518 (avg: 0.0034) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 183 [100/192] | loss: 0.5980 (avg: 0.3109) | acc: 0.9727 (avg: 0.9747) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4530 |\n",
      "Epoch 184 [0/192] | loss: 0.5748 (avg: 0.0030) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 184 [100/192] | loss: 0.5179 (avg: 0.2974) | acc: 0.9805 (avg: 0.9775) |\n",
      "Validation | acc (nat): 0.8040 | acc (rob): 0.4500 |\n",
      "Epoch 185 [0/192] | loss: 0.5578 (avg: 0.0029) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 185 [100/192] | loss: 0.5747 (avg: 0.3026) | acc: 0.9727 (avg: 0.9762) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4460 |\n",
      "Epoch 186 [0/192] | loss: 0.7347 (avg: 0.0038) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 186 [100/192] | loss: 0.6571 (avg: 0.3057) | acc: 0.9688 (avg: 0.9749) |\n",
      "Validation | acc (nat): 0.8170 | acc (rob): 0.4630 |\n",
      "Epoch 187 [0/192] | loss: 0.5176 (avg: 0.0027) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 187 [100/192] | loss: 0.5295 (avg: 0.2922) | acc: 0.9805 (avg: 0.9778) |\n",
      "Validation | acc (nat): 0.7930 | acc (rob): 0.4360 |\n",
      "Epoch 188 [0/192] | loss: 0.4363 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 188 [100/192] | loss: 0.5340 (avg: 0.2880) | acc: 0.9805 (avg: 0.9786) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4670 |\n",
      "Epoch 189 [0/192] | loss: 0.5805 (avg: 0.0030) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 189 [100/192] | loss: 0.5613 (avg: 0.3076) | acc: 0.9766 (avg: 0.9740) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4630 |\n",
      "Epoch 190 [0/192] | loss: 0.4919 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 190 [100/192] | loss: 0.5298 (avg: 0.3061) | acc: 0.9766 (avg: 0.9744) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4520 |\n",
      "Epoch 191 [0/192] | loss: 0.4886 (avg: 0.0025) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 191 [100/192] | loss: 0.5695 (avg: 0.2877) | acc: 0.9766 (avg: 0.9780) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4460 |\n",
      "Epoch 192 [0/192] | loss: 0.5167 (avg: 0.0027) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 192 [100/192] | loss: 0.7020 (avg: 0.2977) | acc: 0.9648 (avg: 0.9763) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4510 |\n",
      "Epoch 193 [0/192] | loss: 0.5600 (avg: 0.0029) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 193 [100/192] | loss: 0.5235 (avg: 0.3125) | acc: 0.9805 (avg: 0.9727) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4280 |\n",
      "Epoch 194 [0/192] | loss: 0.5893 (avg: 0.0031) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 194 [100/192] | loss: 0.6963 (avg: 0.2973) | acc: 0.9609 (avg: 0.9759) |\n",
      "Validation | acc (nat): 0.8190 | acc (rob): 0.4450 |\n",
      "Epoch 195 [0/192] | loss: 0.5217 (avg: 0.0027) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 195 [100/192] | loss: 0.5789 (avg: 0.2996) | acc: 0.9766 (avg: 0.9754) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4620 |\n",
      "Epoch 196 [0/192] | loss: 0.6023 (avg: 0.0031) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 196 [100/192] | loss: 0.6434 (avg: 0.2921) | acc: 0.9648 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4450 |\n",
      "Epoch 197 [0/192] | loss: 0.5595 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 197 [100/192] | loss: 0.5269 (avg: 0.2919) | acc: 0.9805 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4460 |\n",
      "Epoch 198 [0/192] | loss: 0.4467 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 198 [100/192] | loss: 0.4723 (avg: 0.2876) | acc: 0.9844 (avg: 0.9772) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4730 |\n",
      "Epoch 199 [0/192] | loss: 0.5904 (avg: 0.0031) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 199 [100/192] | loss: 0.5153 (avg: 0.2881) | acc: 0.9805 (avg: 0.9768) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4530 |\n",
      "Epoch 200 [0/192] | loss: 0.5881 (avg: 0.0031) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 200 [100/192] | loss: 0.4562 (avg: 0.2930) | acc: 0.9844 (avg: 0.9756) |\n",
      "Validation | acc (nat): 0.7860 | acc (rob): 0.4550 |\n",
      "Epoch 201 [0/192] | loss: 0.4527 (avg: 0.0024) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 201 [100/192] | loss: 0.5472 (avg: 0.2838) | acc: 0.9844 (avg: 0.9773) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4570 |\n",
      "Epoch 202 [0/192] | loss: 0.5180 (avg: 0.0027) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 202 [100/192] | loss: 0.6312 (avg: 0.2914) | acc: 0.9648 (avg: 0.9756) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4560 |\n",
      "Epoch 203 [0/192] | loss: 0.5283 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 203 [100/192] | loss: 0.7284 (avg: 0.2959) | acc: 0.9609 (avg: 0.9746) |\n",
      "Validation | acc (nat): 0.7890 | acc (rob): 0.4490 |\n",
      "Epoch 204 [0/192] | loss: 0.5422 (avg: 0.0028) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 204 [100/192] | loss: 0.4259 (avg: 0.2853) | acc: 0.9922 (avg: 0.9772) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4460 |\n",
      "Epoch 205 [0/192] | loss: 0.5089 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 205 [100/192] | loss: 0.5043 (avg: 0.2923) | acc: 0.9805 (avg: 0.9753) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4390 |\n",
      "Epoch 206 [0/192] | loss: 0.4585 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 206 [100/192] | loss: 0.5660 (avg: 0.2913) | acc: 0.9727 (avg: 0.9751) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4480 |\n",
      "Epoch 207 [0/192] | loss: 0.5061 (avg: 0.0026) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 207 [100/192] | loss: 0.6208 (avg: 0.2930) | acc: 0.9688 (avg: 0.9752) |\n",
      "Validation | acc (nat): 0.7860 | acc (rob): 0.4570 |\n",
      "Epoch 208 [0/192] | loss: 0.4714 (avg: 0.0025) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 208 [100/192] | loss: 0.5912 (avg: 0.2855) | acc: 0.9727 (avg: 0.9771) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4530 |\n",
      "Epoch 209 [0/192] | loss: 0.4947 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 209 [100/192] | loss: 0.5779 (avg: 0.2954) | acc: 0.9688 (avg: 0.9749) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4530 |\n",
      "Epoch 210 [0/192] | loss: 0.6257 (avg: 0.0033) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 210 [100/192] | loss: 0.5441 (avg: 0.2979) | acc: 0.9727 (avg: 0.9745) |\n",
      "Validation | acc (nat): 0.7930 | acc (rob): 0.4380 |\n",
      "Epoch 211 [0/192] | loss: 0.4996 (avg: 0.0026) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 211 [100/192] | loss: 0.5964 (avg: 0.3044) | acc: 0.9688 (avg: 0.9728) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4560 |\n",
      "Epoch 212 [0/192] | loss: 0.4890 (avg: 0.0025) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 212 [100/192] | loss: 0.5941 (avg: 0.2830) | acc: 0.9727 (avg: 0.9774) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4420 |\n",
      "Epoch 213 [0/192] | loss: 0.5455 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 213 [100/192] | loss: 0.5951 (avg: 0.2856) | acc: 0.9727 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4730 |\n",
      "Epoch 214 [0/192] | loss: 0.4993 (avg: 0.0026) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 214 [100/192] | loss: 0.5204 (avg: 0.2999) | acc: 0.9766 (avg: 0.9737) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4390 |\n",
      "Epoch 215 [0/192] | loss: 0.5172 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 215 [100/192] | loss: 0.3934 (avg: 0.2807) | acc: 0.9922 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4410 |\n",
      "Epoch 216 [0/192] | loss: 0.6531 (avg: 0.0034) | acc: 0.9648 (avg: 0.9648) |\n",
      "Epoch 216 [100/192] | loss: 0.4724 (avg: 0.2915) | acc: 0.9844 (avg: 0.9747) |\n",
      "Validation | acc (nat): 0.8120 | acc (rob): 0.4620 |\n",
      "Epoch 217 [0/192] | loss: 0.5557 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 217 [100/192] | loss: 0.7685 (avg: 0.2741) | acc: 0.9492 (avg: 0.9785) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4480 |\n",
      "Epoch 218 [0/192] | loss: 0.5394 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 218 [100/192] | loss: 0.5055 (avg: 0.2811) | acc: 0.9805 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4500 |\n",
      "Epoch 219 [0/192] | loss: 0.5419 (avg: 0.0028) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 219 [100/192] | loss: 0.5005 (avg: 0.2871) | acc: 0.9844 (avg: 0.9752) |\n",
      "Validation | acc (nat): 0.8240 | acc (rob): 0.4610 |\n",
      "Epoch 220 [0/192] | loss: 0.5040 (avg: 0.0026) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 220 [100/192] | loss: 0.5944 (avg: 0.2893) | acc: 0.9688 (avg: 0.9748) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4610 |\n",
      "Epoch 221 [0/192] | loss: 0.6270 (avg: 0.0033) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 221 [100/192] | loss: 0.4711 (avg: 0.3043) | acc: 0.9844 (avg: 0.9723) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4530 |\n",
      "Epoch 222 [0/192] | loss: 0.5240 (avg: 0.0027) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 222 [100/192] | loss: 0.5428 (avg: 0.2803) | acc: 0.9766 (avg: 0.9767) |\n",
      "Validation | acc (nat): 0.7900 | acc (rob): 0.4490 |\n",
      "Epoch 223 [0/192] | loss: 0.5572 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 223 [100/192] | loss: 0.4815 (avg: 0.2812) | acc: 0.9805 (avg: 0.9766) |\n",
      "Validation | acc (nat): 0.7880 | acc (rob): 0.4560 |\n",
      "Epoch 224 [0/192] | loss: 0.5236 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 224 [100/192] | loss: 0.4371 (avg: 0.2841) | acc: 0.9883 (avg: 0.9759) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4500 |\n",
      "Epoch 225 [0/192] | loss: 0.4877 (avg: 0.0025) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 225 [100/192] | loss: 0.6176 (avg: 0.2970) | acc: 0.9688 (avg: 0.9734) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4460 |\n",
      "Epoch 226 [0/192] | loss: 0.5777 (avg: 0.0030) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 226 [100/192] | loss: 0.6181 (avg: 0.2966) | acc: 0.9688 (avg: 0.9734) |\n",
      "Validation | acc (nat): 0.7900 | acc (rob): 0.4570 |\n",
      "Epoch 227 [0/192] | loss: 0.5443 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 227 [100/192] | loss: 0.5404 (avg: 0.2800) | acc: 0.9727 (avg: 0.9768) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4340 |\n",
      "Epoch 228 [0/192] | loss: 0.5448 (avg: 0.0028) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 228 [100/192] | loss: 0.5872 (avg: 0.2845) | acc: 0.9688 (avg: 0.9756) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4560 |\n",
      "Epoch 229 [0/192] | loss: 0.6393 (avg: 0.0033) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 229 [100/192] | loss: 0.5051 (avg: 0.2907) | acc: 0.9805 (avg: 0.9749) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4520 |\n",
      "Epoch 230 [0/192] | loss: 0.5584 (avg: 0.0029) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 230 [100/192] | loss: 0.5527 (avg: 0.2908) | acc: 0.9766 (avg: 0.9744) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4770 |\n",
      "Epoch 231 [0/192] | loss: 0.5753 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 231 [100/192] | loss: 0.4562 (avg: 0.2870) | acc: 0.9844 (avg: 0.9748) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4540 |\n",
      "Epoch 232 [0/192] | loss: 0.4409 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 232 [100/192] | loss: 0.7153 (avg: 0.2996) | acc: 0.9531 (avg: 0.9724) |\n",
      "Validation | acc (nat): 0.7860 | acc (rob): 0.4420 |\n",
      "Epoch 233 [0/192] | loss: 0.5478 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 233 [100/192] | loss: 0.5074 (avg: 0.2909) | acc: 0.9805 (avg: 0.9741) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4400 |\n",
      "Epoch 234 [0/192] | loss: 0.4749 (avg: 0.0025) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 234 [100/192] | loss: 0.5672 (avg: 0.2838) | acc: 0.9727 (avg: 0.9758) |\n",
      "Validation | acc (nat): 0.7890 | acc (rob): 0.4360 |\n",
      "Epoch 235 [0/192] | loss: 0.6165 (avg: 0.0032) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 235 [100/192] | loss: 0.6096 (avg: 0.2963) | acc: 0.9688 (avg: 0.9729) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4420 |\n",
      "Epoch 236 [0/192] | loss: 0.5300 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 236 [100/192] | loss: 0.5427 (avg: 0.2784) | acc: 0.9766 (avg: 0.9762) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4410 |\n",
      "Epoch 237 [0/192] | loss: 0.5353 (avg: 0.0028) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 237 [100/192] | loss: 0.5722 (avg: 0.2770) | acc: 0.9688 (avg: 0.9770) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4540 |\n",
      "Epoch 238 [0/192] | loss: 0.4616 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 238 [100/192] | loss: 0.5548 (avg: 0.2752) | acc: 0.9727 (avg: 0.9767) |\n",
      "Validation | acc (nat): 0.8040 | acc (rob): 0.4390 |\n",
      "Epoch 239 [0/192] | loss: 0.5928 (avg: 0.0031) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 239 [100/192] | loss: 0.3886 (avg: 0.2769) | acc: 0.9922 (avg: 0.9770) |\n",
      "Validation | acc (nat): 0.7810 | acc (rob): 0.4620 |\n",
      "Epoch 240 [0/192] | loss: 0.4556 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 240 [100/192] | loss: 0.4149 (avg: 0.2856) | acc: 0.9922 (avg: 0.9747) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4610 |\n",
      "Epoch 241 [0/192] | loss: 0.5289 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 241 [100/192] | loss: 0.6549 (avg: 0.2768) | acc: 0.9688 (avg: 0.9768) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4380 |\n",
      "Epoch 242 [0/192] | loss: 0.5518 (avg: 0.0029) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 242 [100/192] | loss: 0.4672 (avg: 0.2842) | acc: 0.9844 (avg: 0.9749) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4550 |\n",
      "Epoch 243 [0/192] | loss: 0.5075 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 243 [100/192] | loss: 0.5448 (avg: 0.2838) | acc: 0.9766 (avg: 0.9751) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4680 |\n",
      "Epoch 244 [0/192] | loss: 0.4924 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 244 [100/192] | loss: 0.5553 (avg: 0.2793) | acc: 0.9766 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4640 |\n",
      "Epoch 245 [0/192] | loss: 0.4904 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 245 [100/192] | loss: 0.4822 (avg: 0.2674) | acc: 0.9805 (avg: 0.9785) |\n",
      "Validation | acc (nat): 0.8100 | acc (rob): 0.4630 |\n",
      "Epoch 246 [0/192] | loss: 0.5690 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 246 [100/192] | loss: 0.4687 (avg: 0.2746) | acc: 0.9805 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4500 |\n",
      "Epoch 247 [0/192] | loss: 0.5839 (avg: 0.0030) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 247 [100/192] | loss: 0.5662 (avg: 0.2733) | acc: 0.9727 (avg: 0.9779) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4650 |\n",
      "Epoch 248 [0/192] | loss: 0.5427 (avg: 0.0028) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 248 [100/192] | loss: 0.6123 (avg: 0.2779) | acc: 0.9648 (avg: 0.9764) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4590 |\n",
      "Epoch 249 [0/192] | loss: 0.5082 (avg: 0.0026) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 249 [100/192] | loss: 0.4969 (avg: 0.2793) | acc: 0.9766 (avg: 0.9764) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4620 |\n",
      "Epoch 250 [0/192] | loss: 0.5545 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 250 [100/192] | loss: 0.4089 (avg: 0.2795) | acc: 0.9922 (avg: 0.9763) |\n",
      "Validation | acc (nat): 0.7930 | acc (rob): 0.4700 |\n",
      "Epoch 251 [0/192] | loss: 0.5275 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 251 [100/192] | loss: 0.5661 (avg: 0.2952) | acc: 0.9688 (avg: 0.9733) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4530 |\n",
      "Epoch 252 [0/192] | loss: 0.4753 (avg: 0.0025) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 252 [100/192] | loss: 0.5638 (avg: 0.2779) | acc: 0.9727 (avg: 0.9761) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4470 |\n",
      "Epoch 253 [0/192] | loss: 0.5586 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 253 [100/192] | loss: 0.6332 (avg: 0.2650) | acc: 0.9648 (avg: 0.9789) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4710 |\n",
      "Epoch 254 [0/192] | loss: 0.5599 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 254 [100/192] | loss: 0.5566 (avg: 0.2823) | acc: 0.9766 (avg: 0.9756) |\n",
      "Validation | acc (nat): 0.8170 | acc (rob): 0.4550 |\n",
      "Epoch 255 [0/192] | loss: 0.4654 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 255 [100/192] | loss: 0.6001 (avg: 0.2710) | acc: 0.9727 (avg: 0.9775) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4450 |\n",
      "Epoch 256 [0/192] | loss: 0.5774 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 256 [100/192] | loss: 0.6153 (avg: 0.2887) | acc: 0.9688 (avg: 0.9743) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4410 |\n",
      "Epoch 257 [0/192] | loss: 0.5694 (avg: 0.0030) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 257 [100/192] | loss: 0.4770 (avg: 0.2790) | acc: 0.9805 (avg: 0.9759) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4540 |\n",
      "Epoch 258 [0/192] | loss: 0.5034 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 258 [100/192] | loss: 0.4160 (avg: 0.2817) | acc: 0.9922 (avg: 0.9753) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4490 |\n",
      "Epoch 259 [0/192] | loss: 0.6632 (avg: 0.0035) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 259 [100/192] | loss: 0.3852 (avg: 0.2753) | acc: 0.9922 (avg: 0.9767) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4700 |\n",
      "Epoch 260 [0/192] | loss: 0.4866 (avg: 0.0025) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 260 [100/192] | loss: 0.5343 (avg: 0.2603) | acc: 0.9727 (avg: 0.9793) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4700 |\n",
      "Epoch 261 [0/192] | loss: 0.3985 (avg: 0.0021) | acc: 0.9922 (avg: 0.9922) |\n",
      "Epoch 261 [100/192] | loss: 0.4695 (avg: 0.2721) | acc: 0.9805 (avg: 0.9768) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4740 |\n",
      "Epoch 262 [0/192] | loss: 0.5437 (avg: 0.0028) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 262 [100/192] | loss: 0.5172 (avg: 0.2698) | acc: 0.9727 (avg: 0.9776) |\n",
      "Validation | acc (nat): 0.8040 | acc (rob): 0.4510 |\n",
      "Epoch 263 [0/192] | loss: 0.5762 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 263 [100/192] | loss: 0.7056 (avg: 0.2675) | acc: 0.9531 (avg: 0.9774) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4490 |\n",
      "Epoch 264 [0/192] | loss: 0.6110 (avg: 0.0032) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 264 [100/192] | loss: 0.4950 (avg: 0.2878) | acc: 0.9805 (avg: 0.9738) |\n",
      "Validation | acc (nat): 0.7920 | acc (rob): 0.4410 |\n",
      "Epoch 265 [0/192] | loss: 0.4788 (avg: 0.0025) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 265 [100/192] | loss: 0.4996 (avg: 0.2876) | acc: 0.9766 (avg: 0.9741) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4580 |\n",
      "Epoch 266 [0/192] | loss: 0.4830 (avg: 0.0025) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 266 [100/192] | loss: 0.4760 (avg: 0.2832) | acc: 0.9805 (avg: 0.9749) |\n",
      "Validation | acc (nat): 0.7870 | acc (rob): 0.4520 |\n",
      "Epoch 267 [0/192] | loss: 0.5392 (avg: 0.0028) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 267 [100/192] | loss: 0.6825 (avg: 0.2886) | acc: 0.9609 (avg: 0.9735) |\n",
      "Validation | acc (nat): 0.8150 | acc (rob): 0.4630 |\n",
      "Epoch 268 [0/192] | loss: 0.5001 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 268 [100/192] | loss: 0.5604 (avg: 0.2701) | acc: 0.9727 (avg: 0.9774) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4500 |\n",
      "Epoch 269 [0/192] | loss: 0.3988 (avg: 0.0021) | acc: 0.9922 (avg: 0.9922) |\n",
      "Epoch 269 [100/192] | loss: 0.4746 (avg: 0.2790) | acc: 0.9844 (avg: 0.9757) |\n",
      "Validation | acc (nat): 0.7910 | acc (rob): 0.4270 |\n",
      "Epoch 270 [0/192] | loss: 0.5241 (avg: 0.0027) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 270 [100/192] | loss: 0.5545 (avg: 0.2895) | acc: 0.9727 (avg: 0.9733) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4350 |\n",
      "Epoch 271 [0/192] | loss: 0.5592 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 271 [100/192] | loss: 0.5085 (avg: 0.2744) | acc: 0.9805 (avg: 0.9766) |\n",
      "Validation | acc (nat): 0.7910 | acc (rob): 0.4450 |\n",
      "Epoch 272 [0/192] | loss: 0.4556 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 272 [100/192] | loss: 0.5785 (avg: 0.2804) | acc: 0.9688 (avg: 0.9752) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4530 |\n",
      "Epoch 273 [0/192] | loss: 0.3746 (avg: 0.0020) | acc: 0.9922 (avg: 0.9922) |\n",
      "Epoch 273 [100/192] | loss: 0.5180 (avg: 0.2850) | acc: 0.9805 (avg: 0.9742) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4620 |\n",
      "Epoch 274 [0/192] | loss: 0.4298 (avg: 0.0022) | acc: 0.9922 (avg: 0.9922) |\n",
      "Epoch 274 [100/192] | loss: 0.4335 (avg: 0.2880) | acc: 0.9883 (avg: 0.9744) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4520 |\n",
      "Epoch 275 [0/192] | loss: 0.5138 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 275 [100/192] | loss: 0.5332 (avg: 0.2692) | acc: 0.9766 (avg: 0.9772) |\n",
      "Validation | acc (nat): 0.8110 | acc (rob): 0.4430 |\n",
      "Epoch 276 [0/192] | loss: 0.5510 (avg: 0.0029) | acc: 0.9727 (avg: 0.9727) |\n",
      "Epoch 276 [100/192] | loss: 0.5798 (avg: 0.2864) | acc: 0.9727 (avg: 0.9739) |\n",
      "Validation | acc (nat): 0.8090 | acc (rob): 0.4620 |\n",
      "Epoch 277 [0/192] | loss: 0.5791 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 277 [100/192] | loss: 0.4879 (avg: 0.2863) | acc: 0.9805 (avg: 0.9742) |\n",
      "Validation | acc (nat): 0.8150 | acc (rob): 0.4470 |\n",
      "Epoch 278 [0/192] | loss: 0.6560 (avg: 0.0034) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 278 [100/192] | loss: 0.4252 (avg: 0.2632) | acc: 0.9844 (avg: 0.9784) |\n",
      "Validation | acc (nat): 0.8020 | acc (rob): 0.4470 |\n",
      "Epoch 279 [0/192] | loss: 0.4698 (avg: 0.0024) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 279 [100/192] | loss: 0.5634 (avg: 0.2651) | acc: 0.9727 (avg: 0.9781) |\n",
      "Validation | acc (nat): 0.8010 | acc (rob): 0.4690 |\n",
      "Epoch 280 [0/192] | loss: 0.5889 (avg: 0.0031) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 280 [100/192] | loss: 0.5454 (avg: 0.2669) | acc: 0.9766 (avg: 0.9780) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4500 |\n",
      "Epoch 281 [0/192] | loss: 0.4736 (avg: 0.0025) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 281 [100/192] | loss: 0.5536 (avg: 0.2589) | acc: 0.9727 (avg: 0.9795) |\n",
      "Validation | acc (nat): 0.7870 | acc (rob): 0.4660 |\n",
      "Epoch 282 [0/192] | loss: 0.4416 (avg: 0.0023) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 282 [100/192] | loss: 0.5444 (avg: 0.2762) | acc: 0.9727 (avg: 0.9758) |\n",
      "Validation | acc (nat): 0.7940 | acc (rob): 0.4730 |\n",
      "Epoch 283 [0/192] | loss: 0.4442 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 283 [100/192] | loss: 0.4863 (avg: 0.2749) | acc: 0.9805 (avg: 0.9764) |\n",
      "Validation | acc (nat): 0.7770 | acc (rob): 0.4610 |\n",
      "Epoch 284 [0/192] | loss: 0.6627 (avg: 0.0035) | acc: 0.9609 (avg: 0.9609) |\n",
      "Epoch 284 [100/192] | loss: 0.5815 (avg: 0.2708) | acc: 0.9609 (avg: 0.9768) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4600 |\n",
      "Epoch 285 [0/192] | loss: 0.5713 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 285 [100/192] | loss: 0.5815 (avg: 0.2794) | acc: 0.9766 (avg: 0.9753) |\n",
      "Validation | acc (nat): 0.8000 | acc (rob): 0.4650 |\n",
      "Epoch 286 [0/192] | loss: 0.4496 (avg: 0.0023) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 286 [100/192] | loss: 0.5318 (avg: 0.2703) | acc: 0.9766 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.8120 | acc (rob): 0.4760 |\n",
      "Epoch 287 [0/192] | loss: 0.5841 (avg: 0.0030) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 287 [100/192] | loss: 0.5067 (avg: 0.2704) | acc: 0.9766 (avg: 0.9769) |\n",
      "Validation | acc (nat): 0.7770 | acc (rob): 0.4580 |\n",
      "Epoch 288 [0/192] | loss: 0.5130 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 288 [100/192] | loss: 0.4147 (avg: 0.2636) | acc: 0.9883 (avg: 0.9780) |\n",
      "Validation | acc (nat): 0.7980 | acc (rob): 0.4690 |\n",
      "Epoch 289 [0/192] | loss: 0.4112 (avg: 0.0021) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 289 [100/192] | loss: 0.4064 (avg: 0.2913) | acc: 0.9883 (avg: 0.9730) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4570 |\n",
      "Epoch 290 [0/192] | loss: 0.5866 (avg: 0.0031) | acc: 0.9688 (avg: 0.9688) |\n",
      "Epoch 290 [100/192] | loss: 0.4082 (avg: 0.2847) | acc: 0.9883 (avg: 0.9742) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4650 |\n",
      "Epoch 291 [0/192] | loss: 0.4624 (avg: 0.0024) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 291 [100/192] | loss: 0.6750 (avg: 0.2624) | acc: 0.9609 (avg: 0.9786) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4590 |\n",
      "Epoch 292 [0/192] | loss: 0.4475 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 292 [100/192] | loss: 0.4894 (avg: 0.2858) | acc: 0.9805 (avg: 0.9739) |\n",
      "Validation | acc (nat): 0.7970 | acc (rob): 0.4410 |\n",
      "Epoch 293 [0/192] | loss: 0.3890 (avg: 0.0020) | acc: 0.9922 (avg: 0.9922) |\n",
      "Epoch 293 [100/192] | loss: 0.4757 (avg: 0.2772) | acc: 0.9805 (avg: 0.9758) |\n",
      "Validation | acc (nat): 0.7960 | acc (rob): 0.4650 |\n",
      "Epoch 294 [0/192] | loss: 0.4642 (avg: 0.0024) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 294 [100/192] | loss: 0.5194 (avg: 0.2668) | acc: 0.9727 (avg: 0.9775) |\n",
      "Validation | acc (nat): 0.7990 | acc (rob): 0.4750 |\n",
      "Epoch 295 [0/192] | loss: 0.5020 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 295 [100/192] | loss: 0.6208 (avg: 0.2714) | acc: 0.9609 (avg: 0.9765) |\n",
      "Validation | acc (nat): 0.7950 | acc (rob): 0.4790 |\n",
      "Epoch 296 [0/192] | loss: 0.4986 (avg: 0.0026) | acc: 0.9805 (avg: 0.9805) |\n",
      "Epoch 296 [100/192] | loss: 0.6484 (avg: 0.2691) | acc: 0.9609 (avg: 0.9770) |\n",
      "Validation | acc (nat): 0.8060 | acc (rob): 0.4660 |\n",
      "Epoch 297 [0/192] | loss: 0.5250 (avg: 0.0027) | acc: 0.9766 (avg: 0.9766) |\n",
      "Epoch 297 [100/192] | loss: 0.5801 (avg: 0.2936) | acc: 0.9688 (avg: 0.9724) |\n",
      "Validation | acc (nat): 0.8030 | acc (rob): 0.4460 |\n",
      "Epoch 298 [0/192] | loss: 0.4410 (avg: 0.0023) | acc: 0.9883 (avg: 0.9883) |\n",
      "Epoch 298 [100/192] | loss: 0.5804 (avg: 0.2757) | acc: 0.9727 (avg: 0.9756) |\n",
      "Validation | acc (nat): 0.8050 | acc (rob): 0.4600 |\n",
      "Epoch 299 [0/192] | loss: 0.4139 (avg: 0.0022) | acc: 0.9844 (avg: 0.9844) |\n",
      "Epoch 299 [100/192] | loss: 0.6666 (avg: 0.2775) | acc: 0.9648 (avg: 0.9751) |\n",
      "Validation | acc (nat): 0.8070 | acc (rob): 0.4400 |\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "os.makedirs(checkpoint, exist_ok=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "train_dataset, _ = get_dataloader(dataset, batch_size)\n",
    "num_samples = len(train_dataset)\n",
    "num_samples_for_train = int(num_samples * 0.98)\n",
    "num_samples_for_valid = num_samples - num_samples_for_train\n",
    "train_set, valid_set = random_split(train_dataset, [num_samples_for_train, num_samples_for_valid])\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=1, shuffle=True, drop_last=False)\n",
    "\n",
    "model = nn.DataParallel(get_network(model_type, num_classes).cuda())\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "#adjust_learning_rate = lr_scheduler.MultiStepLR(optimizer, scheduler, gamma=0.1)\n",
    "best_acc_nat, best_acc_rob = 0, 0\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    training(epoch, model, train_dataloader, optimizer, num_classes, xi, lam, warm_up, epsilon, alpha, num_repeats, use_at=True)\n",
    "    test_acc_nat, test_acc_rob = evaluation(epoch, model, valid_dataloader, alpha, epsilon, num_repeats)\n",
    "        \n",
    "    is_best = best_acc_nat < test_acc_nat and best_acc_rob < test_acc_rob\n",
    "    best_acc_nat = max(best_acc_nat, test_acc_nat)\n",
    "    best_acc_rob = max(best_acc_rob, test_acc_rob)\n",
    "    save_checkpoint = {'state_dict': model.state_dict(),\n",
    "                       'best_acc_nat': best_acc_nat,\n",
    "                       'best_acc_rob': best_acc_rob,\n",
    "                       'optimizer': optimizer.state_dict(),\n",
    "                       'model_type': model_type,\n",
    "                       'dataset': dataset}\n",
    "    torch.save(save_checkpoint, os.path.join(checkpoint, 'model'))\n",
    "    if is_best:\n",
    "        torch.save(save_checkpoint, os.path.join(checkpoint, 'best_model'))\n",
    "    #adjust_learning_rate.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67273057-ddb6-4294-b7ae-3aa932ab0cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7396d-f39a-4f94-8ab0-d6157b5ef951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
