{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be933234-4b51-41a5-a5a0-9b831b916f96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Weighting Minimax Risk (WMMR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85eb3db2-6a80-4e98-8a62-4fd714fc9189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import yaml\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66240c81-1be4-4a34-af22-21a6292e0ff9",
   "metadata": {},
   "source": [
    "## Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01de849e-a804-4062-aef7-4cfcd5999b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = '4,5,6,7'\n",
    "dataset = 'cifar10'\n",
    "model_type = 'wrn34-10'\n",
    "checkpoint = './checkpoint/wmmr/%s/%s' % (model_type, dataset)\n",
    "num_classes = 10\n",
    "lr = 0.2\n",
    "weight_decay = 5e-4\n",
    "batch_size = 128\n",
    "total_epochs = 100\n",
    "tau = 0.5\n",
    "epsilon = 8/255\n",
    "alpha = 2/255\n",
    "num_repeats = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c102405-4d46-45e0-b957-9e7022b7ae2f",
   "metadata": {},
   "source": [
    "## Inner maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee44a0f-0acc-41c3-95a0-e477e167e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_max(model, inputs, targets, epsilon, alpha, num_repeats, tau):\n",
    "    noise = torch.FloatTensor(inputs.shape).normal_(0, 1).cuda()\n",
    "    x = torch.clamp(inputs + 0.001*noise, min=0, max=1)\n",
    "    batch = x.size(0)\n",
    "    model.eval()\n",
    "    for _ in range(num_repeats):\n",
    "        x.requires_grad_()\n",
    "        with torch.enable_grad():\n",
    "            logits = model(x)\n",
    "        \n",
    "        classes = torch.arange(logits.size(1))[None,:].repeat(batch,1).cuda()\n",
    "        false_probs = logits.softmax(dim=1)[classes!=targets[:,None]].view(batch, logits.size(1)-1)\n",
    "        gt_probs = logits.softmax(dim=1)[classes==targets[:,None]].unsqueeze(1)\n",
    "        top2_probs = torch.topk(false_probs, k=1).values\n",
    "        s = torch.exp(-tau*(gt_probs - top2_probs)).view(-1)\n",
    "        \n",
    "        loss = -torch.sum(s*torch.log_softmax(logits, dim=1)[classes==targets[:,None]])/batch\n",
    "        loss.backward()\n",
    "        grads = x.grad.data\n",
    "        x = x.data.detach() + alpha*torch.sign(grads).detach()\n",
    "        x = torch.min(torch.max(x, inputs-epsilon), inputs+epsilon).clamp(min=0, max=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe2591b-4ebf-4714-a3f4-85cdac7f272d",
   "metadata": {},
   "source": [
    "## Training (Outer minimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2276c9-d52b-4544-8448-42817161084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epoch, model, dataloader, optimizer, num_classes, \n",
    "             tau=2.0, epsilon=8/255, alpha=2/255, num_repeats=10):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "        \n",
    "    for idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        batch = inputs.size(0)\n",
    "        \n",
    "        x = inner_max(model, inputs, targets, epsilon, alpha, num_repeats, tau)\n",
    "        model.train()\n",
    "        logits = model(x)\n",
    "        \n",
    "        classes = torch.arange(num_classes)[None,:].repeat(batch,1).cuda()\n",
    "        false_probs = logits.softmax(dim=1)[classes!=targets[:,None]].view(batch, logits.size(1)-1)\n",
    "        gt_probs = logits.softmax(dim=1)[classes==targets[:,None]].unsqueeze(1)\n",
    "        top2_probs = torch.topk(false_probs, k=1).values\n",
    "        s = torch.exp(-tau*(gt_probs - top2_probs)).view(-1)\n",
    "        \n",
    "        loss = -torch.sum(s*torch.log_softmax(logits, dim=1)[classes==targets[:,None]])/batch\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        total += batch\n",
    "        total_loss += loss.item()\n",
    "        num_correct = torch.argmax(logits.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "        total_correct += num_correct\n",
    "        \n",
    "        if idx % 100 == 0:\n",
    "            print('Epoch %d [%d/%d] | loss: %.4f (avg: %.4f) | acc: %.4f (avg: %.4f) |'\\\n",
    "                  % (epoch, idx, len(dataloader), loss.item(), total_loss/(idx+1),\n",
    "                     num_correct/batch, total_correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff1c8d2-8e9c-441c-b471-9eb237eb3bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(epoch, model, dataloader, alpha, epsilon, num_repeats):\n",
    "    model.eval()\n",
    "    total_correct_nat = 0\n",
    "    total_correct_adv = 0\n",
    "    \n",
    "    xent = nn.CrossEntropyLoss()\n",
    "    with tqdm(dataloader) as pbar:\n",
    "        for index, (inputs, targets) in enumerate(pbar):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            batch = inputs.size(0)\n",
    "            pbar.set_description(\"[eval] %d/%d\" % (index+1, len(dataloader.dataset)))\n",
    "            \n",
    "            noise = torch.FloatTensor(inputs.shape).uniform_(-1, 1).cuda()\n",
    "            x = torch.clamp(inputs+noise, min=0, max=1)\n",
    "            for _ in range(num_repeats):\n",
    "                x.requires_grad_()\n",
    "                with torch.enable_grad():\n",
    "                    logits = model(x)\n",
    "                loss = xent(logits, targets)\n",
    "                loss.backward()\n",
    "                grads = x.grad.data\n",
    "                x = x.data.detach() + alpha*torch.sign(grads).detach()\n",
    "                x = torch.min(torch.max(x, inputs-epsilon), inputs+epsilon).clamp(min=0,max=1)\n",
    "                \n",
    "            delta = x - inputs\n",
    "            x = torch.clamp(inputs+delta, min=0, max=1)\n",
    "            with torch.no_grad():\n",
    "                logits_nat = model(inputs)\n",
    "                logits_adv = model(x)\n",
    "            total_correct_nat += torch.argmax(logits_nat.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "            total_correct_adv += torch.argmax(logits_adv.data, dim=1).eq(targets.data).cpu().sum().item()\n",
    "            pbar.set_postfix(OrderedDict(acc_nat=total_correct_nat / len(dataloader.dataset),\n",
    "                                         acc_rob=total_correct_adv / len(dataloader.dataset)))\n",
    "    \n",
    "    return (total_correct_nat / len(dataloader.dataset)), (total_correct_adv / len(dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f000e-cb35-4ad5-93d5-fe47f788b266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0 [0/383] | loss: 2.3725 (avg: 2.3725) | acc: 0.1016 (avg: 0.1016) |\n",
      "Epoch 0 [100/383] | loss: 2.3097 (avg: 3.3160) | acc: 0.1016 (avg: 0.1069) |\n",
      "Epoch 0 [200/383] | loss: 2.2830 (avg: 2.8140) | acc: 0.1328 (avg: 0.1103) |\n",
      "Epoch 0 [300/383] | loss: 2.2870 (avg: 2.6386) | acc: 0.1562 (avg: 0.1199) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.05it/s, acc_nat=0.161, acc_rob=0.133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [0/383] | loss: 2.2590 (avg: 2.2590) | acc: 0.1484 (avg: 0.1484) |\n",
      "Epoch 1 [100/383] | loss: 2.2301 (avg: 2.2473) | acc: 0.2109 (avg: 0.1726) |\n",
      "Epoch 1 [200/383] | loss: 2.1746 (avg: 2.2452) | acc: 0.1562 (avg: 0.1729) |\n",
      "Epoch 1 [300/383] | loss: 2.1588 (avg: 2.2427) | acc: 0.2109 (avg: 0.1726) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:19<00:00,  5.02it/s, acc_nat=0.21, acc_rob=0.172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 [0/383] | loss: 2.1794 (avg: 2.1794) | acc: 0.1719 (avg: 0.1719) |\n",
      "Epoch 2 [100/383] | loss: 2.2136 (avg: 2.2152) | acc: 0.1641 (avg: 0.1876) |\n",
      "Epoch 2 [200/383] | loss: 2.1638 (avg: 2.2053) | acc: 0.2031 (avg: 0.1913) |\n",
      "Epoch 2 [300/383] | loss: 2.1612 (avg: 2.2028) | acc: 0.2031 (avg: 0.1942) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:16<00:00,  5.09it/s, acc_nat=0.276, acc_rob=0.216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 [0/383] | loss: 2.1759 (avg: 2.1759) | acc: 0.1719 (avg: 0.1719) |\n",
      "Epoch 3 [100/383] | loss: 2.1000 (avg: 2.1727) | acc: 0.2891 (avg: 0.2148) |\n",
      "Epoch 3 [200/383] | loss: 2.1992 (avg: 2.1617) | acc: 0.1328 (avg: 0.2192) |\n",
      "Epoch 3 [300/383] | loss: 2.1092 (avg: 2.1543) | acc: 0.2500 (avg: 0.2215) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:24<00:00,  4.88it/s, acc_nat=0.3, acc_rob=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 [0/383] | loss: 2.1085 (avg: 2.1085) | acc: 0.2344 (avg: 0.2344) |\n",
      "Epoch 4 [100/383] | loss: 2.0808 (avg: 2.0947) | acc: 0.3125 (avg: 0.2440) |\n",
      "Epoch 4 [200/383] | loss: 2.0876 (avg: 2.0905) | acc: 0.2422 (avg: 0.2470) |\n",
      "Epoch 4 [300/383] | loss: 2.1025 (avg: 2.0910) | acc: 0.2031 (avg: 0.2468) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:14<00:00,  5.15it/s, acc_nat=0.328, acc_rob=0.207]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 [0/383] | loss: 1.9891 (avg: 1.9891) | acc: 0.2422 (avg: 0.2422) |\n",
      "Epoch 5 [100/383] | loss: 2.0722 (avg: 2.0474) | acc: 0.2578 (avg: 0.2689) |\n",
      "Epoch 5 [200/383] | loss: 1.9825 (avg: 2.0460) | acc: 0.2422 (avg: 0.2662) |\n",
      "Epoch 5 [300/383] | loss: 1.9642 (avg: 2.0369) | acc: 0.3359 (avg: 0.2714) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.05it/s, acc_nat=0.369, acc_rob=0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 [0/383] | loss: 2.0579 (avg: 2.0579) | acc: 0.2422 (avg: 0.2422) |\n",
      "Epoch 6 [100/383] | loss: 1.8746 (avg: 2.0007) | acc: 0.3438 (avg: 0.2877) |\n",
      "Epoch 6 [200/383] | loss: 2.0669 (avg: 1.9898) | acc: 0.2734 (avg: 0.2908) |\n",
      "Epoch 6 [300/383] | loss: 2.0303 (avg: 1.9866) | acc: 0.2812 (avg: 0.2934) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:32<00:00,  4.71it/s, acc_nat=0.425, acc_rob=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 [0/383] | loss: 2.0300 (avg: 2.0300) | acc: 0.3359 (avg: 0.3359) |\n",
      "Epoch 7 [100/383] | loss: 1.8888 (avg: 1.9382) | acc: 0.3438 (avg: 0.3149) |\n",
      "Epoch 7 [200/383] | loss: 1.9975 (avg: 1.9387) | acc: 0.2812 (avg: 0.3123) |\n",
      "Epoch 7 [300/383] | loss: 1.8365 (avg: 1.9334) | acc: 0.3672 (avg: 0.3133) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:16<00:00,  5.08it/s, acc_nat=0.432, acc_rob=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 [0/383] | loss: 1.8090 (avg: 1.8090) | acc: 0.3281 (avg: 0.3281) |\n",
      "Epoch 8 [100/383] | loss: 1.9551 (avg: 1.8894) | acc: 0.2500 (avg: 0.3243) |\n",
      "Epoch 8 [200/383] | loss: 1.8454 (avg: 1.8842) | acc: 0.3984 (avg: 0.3289) |\n",
      "Epoch 8 [300/383] | loss: 1.8317 (avg: 1.8756) | acc: 0.2891 (avg: 0.3344) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:21<00:00,  4.97it/s, acc_nat=0.529, acc_rob=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 [0/383] | loss: 1.8604 (avg: 1.8604) | acc: 0.2734 (avg: 0.2734) |\n",
      "Epoch 9 [100/383] | loss: 1.8850 (avg: 1.8455) | acc: 0.2891 (avg: 0.3456) |\n",
      "Epoch 9 [200/383] | loss: 1.9855 (avg: 1.8415) | acc: 0.2266 (avg: 0.3475) |\n",
      "Epoch 9 [300/383] | loss: 1.9436 (avg: 1.8370) | acc: 0.3203 (avg: 0.3480) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:15<00:00,  5.12it/s, acc_nat=0.54, acc_rob=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 [0/383] | loss: 1.8960 (avg: 1.8960) | acc: 0.3828 (avg: 0.3828) |\n",
      "Epoch 10 [100/383] | loss: 1.8504 (avg: 1.8110) | acc: 0.3516 (avg: 0.3612) |\n",
      "Epoch 10 [200/383] | loss: 1.8290 (avg: 1.8107) | acc: 0.3516 (avg: 0.3595) |\n",
      "Epoch 10 [300/383] | loss: 1.8289 (avg: 1.8055) | acc: 0.4062 (avg: 0.3606) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:14<00:00,  5.14it/s, acc_nat=0.546, acc_rob=0.342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 [0/383] | loss: 1.8791 (avg: 1.8791) | acc: 0.3125 (avg: 0.3125) |\n",
      "Epoch 11 [100/383] | loss: 1.7550 (avg: 1.7803) | acc: 0.3750 (avg: 0.3756) |\n",
      "Epoch 11 [200/383] | loss: 1.7806 (avg: 1.7762) | acc: 0.3750 (avg: 0.3711) |\n",
      "Epoch 11 [300/383] | loss: 1.6845 (avg: 1.7772) | acc: 0.3828 (avg: 0.3722) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:20<00:00,  4.99it/s, acc_nat=0.573, acc_rob=0.363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 [0/383] | loss: 1.8224 (avg: 1.8224) | acc: 0.3984 (avg: 0.3984) |\n",
      "Epoch 12 [100/383] | loss: 1.9388 (avg: 1.7638) | acc: 0.3750 (avg: 0.3826) |\n",
      "Epoch 12 [200/383] | loss: 1.7220 (avg: 1.7572) | acc: 0.3828 (avg: 0.3808) |\n",
      "Epoch 12 [300/383] | loss: 1.7079 (avg: 1.7519) | acc: 0.3438 (avg: 0.3830) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:29<00:00,  4.77it/s, acc_nat=0.614, acc_rob=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 [0/383] | loss: 1.6196 (avg: 1.6196) | acc: 0.4844 (avg: 0.4844) |\n",
      "Epoch 13 [100/383] | loss: 1.6891 (avg: 1.7290) | acc: 0.3750 (avg: 0.3891) |\n",
      "Epoch 13 [200/383] | loss: 1.6593 (avg: 1.7226) | acc: 0.3828 (avg: 0.3912) |\n",
      "Epoch 13 [300/383] | loss: 1.7215 (avg: 1.7245) | acc: 0.4219 (avg: 0.3925) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:16<00:00,  5.09it/s, acc_nat=0.598, acc_rob=0.361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 [0/383] | loss: 1.8872 (avg: 1.8872) | acc: 0.3594 (avg: 0.3594) |\n",
      "Epoch 14 [100/383] | loss: 1.6326 (avg: 1.7283) | acc: 0.4609 (avg: 0.3964) |\n",
      "Epoch 14 [200/383] | loss: 1.8049 (avg: 1.7227) | acc: 0.3750 (avg: 0.3951) |\n",
      "Epoch 14 [300/383] | loss: 1.9459 (avg: 1.7213) | acc: 0.3516 (avg: 0.3951) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:20<00:00,  4.98it/s, acc_nat=0.642, acc_rob=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 [0/383] | loss: 1.7782 (avg: 1.7782) | acc: 0.3750 (avg: 0.3750) |\n",
      "Epoch 15 [100/383] | loss: 2.0805 (avg: 1.6959) | acc: 0.2891 (avg: 0.4060) |\n",
      "Epoch 15 [200/383] | loss: 1.8018 (avg: 1.7034) | acc: 0.3906 (avg: 0.4031) |\n",
      "Epoch 15 [300/383] | loss: 1.7866 (avg: 1.6998) | acc: 0.3438 (avg: 0.4032) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:18<00:00,  5.04it/s, acc_nat=0.563, acc_rob=0.355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 [0/383] | loss: 1.7654 (avg: 1.7654) | acc: 0.3828 (avg: 0.3828) |\n",
      "Epoch 16 [100/383] | loss: 1.7647 (avg: 1.6994) | acc: 0.3594 (avg: 0.4062) |\n",
      "Epoch 16 [200/383] | loss: 1.7283 (avg: 1.6862) | acc: 0.4062 (avg: 0.4139) |\n",
      "Epoch 16 [300/383] | loss: 1.7078 (avg: 1.6885) | acc: 0.4062 (avg: 0.4108) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.07it/s, acc_nat=0.647, acc_rob=0.373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 [0/383] | loss: 1.5924 (avg: 1.5924) | acc: 0.4922 (avg: 0.4922) |\n",
      "Epoch 17 [100/383] | loss: 1.5785 (avg: 1.6626) | acc: 0.4297 (avg: 0.4192) |\n",
      "Epoch 17 [200/383] | loss: 1.5745 (avg: 1.6725) | acc: 0.4141 (avg: 0.4154) |\n",
      "Epoch 17 [300/383] | loss: 1.7703 (avg: 1.6747) | acc: 0.3516 (avg: 0.4155) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:16<00:00,  5.09it/s, acc_nat=0.633, acc_rob=0.406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 [0/383] | loss: 1.6950 (avg: 1.6950) | acc: 0.4297 (avg: 0.4297) |\n",
      "Epoch 18 [100/383] | loss: 1.8453 (avg: 1.6582) | acc: 0.3516 (avg: 0.4212) |\n",
      "Epoch 18 [200/383] | loss: 1.8346 (avg: 1.6706) | acc: 0.3125 (avg: 0.4153) |\n",
      "Epoch 18 [300/383] | loss: 1.5863 (avg: 1.6667) | acc: 0.4609 (avg: 0.4165) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:23<00:00,  4.91it/s, acc_nat=0.58, acc_rob=0.311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 [0/383] | loss: 1.6262 (avg: 1.6262) | acc: 0.4297 (avg: 0.4297) |\n",
      "Epoch 19 [100/383] | loss: 1.6017 (avg: 1.6471) | acc: 0.4219 (avg: 0.4226) |\n",
      "Epoch 19 [200/383] | loss: 1.6236 (avg: 1.6534) | acc: 0.3984 (avg: 0.4203) |\n",
      "Epoch 19 [300/383] | loss: 1.6132 (avg: 1.6516) | acc: 0.5000 (avg: 0.4224) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:18<00:00,  5.05it/s, acc_nat=0.609, acc_rob=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 [0/383] | loss: 1.6931 (avg: 1.6931) | acc: 0.3594 (avg: 0.3594) |\n",
      "Epoch 20 [100/383] | loss: 1.6240 (avg: 1.6394) | acc: 0.4766 (avg: 0.4274) |\n",
      "Epoch 20 [200/383] | loss: 1.7019 (avg: 1.6455) | acc: 0.3594 (avg: 0.4263) |\n",
      "Epoch 20 [300/383] | loss: 1.5615 (avg: 1.6478) | acc: 0.4453 (avg: 0.4243) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:30<00:00,  4.76it/s, acc_nat=0.654, acc_rob=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 [0/383] | loss: 1.7155 (avg: 1.7155) | acc: 0.4062 (avg: 0.4062) |\n",
      "Epoch 21 [100/383] | loss: 1.5358 (avg: 1.6419) | acc: 0.5625 (avg: 0.4268) |\n",
      "Epoch 21 [200/383] | loss: 1.4695 (avg: 1.6545) | acc: 0.4766 (avg: 0.4227) |\n",
      "Epoch 21 [300/383] | loss: 1.6768 (avg: 1.6539) | acc: 0.4062 (avg: 0.4227) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.06it/s, acc_nat=0.671, acc_rob=0.423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 [0/383] | loss: 1.6656 (avg: 1.6656) | acc: 0.4609 (avg: 0.4609) |\n",
      "Epoch 22 [100/383] | loss: 1.6271 (avg: 1.6358) | acc: 0.4141 (avg: 0.4196) |\n",
      "Epoch 22 [200/383] | loss: 1.6625 (avg: 1.6401) | acc: 0.4141 (avg: 0.4234) |\n",
      "Epoch 22 [300/383] | loss: 1.7034 (avg: 1.6369) | acc: 0.4531 (avg: 0.4261) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.05it/s, acc_nat=0.62, acc_rob=0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 [0/383] | loss: 1.6529 (avg: 1.6529) | acc: 0.4609 (avg: 0.4609) |\n",
      "Epoch 23 [100/383] | loss: 1.6673 (avg: 1.6299) | acc: 0.4219 (avg: 0.4322) |\n",
      "Epoch 23 [200/383] | loss: 1.7656 (avg: 1.6401) | acc: 0.4141 (avg: 0.4265) |\n",
      "Epoch 23 [300/383] | loss: 1.6064 (avg: 1.6396) | acc: 0.4453 (avg: 0.4288) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:17<00:00,  5.07it/s, acc_nat=0.636, acc_rob=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 [0/383] | loss: 1.5881 (avg: 1.5881) | acc: 0.3984 (avg: 0.3984) |\n",
      "Epoch 24 [100/383] | loss: 1.6722 (avg: 1.6229) | acc: 0.3906 (avg: 0.4329) |\n",
      "Epoch 24 [200/383] | loss: 1.6311 (avg: 1.6313) | acc: 0.4531 (avg: 0.4325) |\n",
      "Epoch 24 [300/383] | loss: 1.6298 (avg: 1.6331) | acc: 0.4844 (avg: 0.4312) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:18<00:00,  5.04it/s, acc_nat=0.629, acc_rob=0.381]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 [0/383] | loss: 1.5446 (avg: 1.5446) | acc: 0.4062 (avg: 0.4062) |\n",
      "Epoch 25 [100/383] | loss: 1.6143 (avg: 1.6355) | acc: 0.4609 (avg: 0.4225) |\n",
      "Epoch 25 [200/383] | loss: 1.6104 (avg: 1.6352) | acc: 0.4453 (avg: 0.4265) |\n",
      "Epoch 25 [300/383] | loss: 1.6010 (avg: 1.6328) | acc: 0.4453 (avg: 0.4292) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:14<00:00,  5.13it/s, acc_nat=0.643, acc_rob=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 [0/383] | loss: 1.5260 (avg: 1.5260) | acc: 0.4062 (avg: 0.4062) |\n",
      "Epoch 26 [100/383] | loss: 1.4798 (avg: 1.5816) | acc: 0.4766 (avg: 0.4437) |\n",
      "Epoch 26 [200/383] | loss: 1.7475 (avg: 1.6089) | acc: 0.4297 (avg: 0.4350) |\n",
      "Epoch 26 [300/383] | loss: 1.6927 (avg: 1.6155) | acc: 0.4453 (avg: 0.4343) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:18<00:00,  5.04it/s, acc_nat=0.661, acc_rob=0.42]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 [0/383] | loss: 1.6101 (avg: 1.6101) | acc: 0.4688 (avg: 0.4688) |\n",
      "Epoch 27 [100/383] | loss: 1.6803 (avg: 1.5961) | acc: 0.4375 (avg: 0.4430) |\n",
      "Epoch 27 [200/383] | loss: 1.5278 (avg: 1.6143) | acc: 0.5078 (avg: 0.4347) |\n",
      "Epoch 27 [300/383] | loss: 1.4625 (avg: 1.6194) | acc: 0.4609 (avg: 0.4324) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:21<00:00,  4.96it/s, acc_nat=0.671, acc_rob=0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 [0/383] | loss: 1.2541 (avg: 1.2541) | acc: 0.6172 (avg: 0.6172) |\n",
      "Epoch 28 [100/383] | loss: 1.5072 (avg: 1.5857) | acc: 0.5156 (avg: 0.4464) |\n",
      "Epoch 28 [200/383] | loss: 1.8309 (avg: 1.6101) | acc: 0.3359 (avg: 0.4420) |\n",
      "Epoch 28 [300/383] | loss: 1.6749 (avg: 1.6214) | acc: 0.4141 (avg: 0.4364) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:15<00:00,  5.11it/s, acc_nat=0.643, acc_rob=0.385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 [0/383] | loss: 1.6181 (avg: 1.6181) | acc: 0.5000 (avg: 0.5000) |\n",
      "Epoch 29 [100/383] | loss: 1.6131 (avg: 1.6097) | acc: 0.3828 (avg: 0.4358) |\n",
      "Epoch 29 [200/383] | loss: 1.7583 (avg: 1.6116) | acc: 0.3906 (avg: 0.4346) |\n",
      "Epoch 29 [300/383] | loss: 1.7274 (avg: 1.6153) | acc: 0.4062 (avg: 0.4361) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:19<00:00,  5.02it/s, acc_nat=0.594, acc_rob=0.384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 [0/383] | loss: 1.5652 (avg: 1.5652) | acc: 0.4609 (avg: 0.4609) |\n",
      "Epoch 30 [100/383] | loss: 1.7773 (avg: 1.6190) | acc: 0.3594 (avg: 0.4354) |\n",
      "Epoch 30 [200/383] | loss: 1.6644 (avg: 1.6058) | acc: 0.3594 (avg: 0.4438) |\n",
      "Epoch 30 [300/383] | loss: 1.5138 (avg: 1.6083) | acc: 0.4844 (avg: 0.4425) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:26<00:00,  4.84it/s, acc_nat=0.658, acc_rob=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 [0/383] | loss: 1.5782 (avg: 1.5782) | acc: 0.4688 (avg: 0.4688) |\n",
      "Epoch 31 [100/383] | loss: 1.4918 (avg: 1.5863) | acc: 0.4922 (avg: 0.4488) |\n",
      "Epoch 31 [200/383] | loss: 1.5415 (avg: 1.5969) | acc: 0.4688 (avg: 0.4435) |\n",
      "Epoch 31 [300/383] | loss: 1.7119 (avg: 1.6080) | acc: 0.4219 (avg: 0.4405) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:14<00:00,  5.13it/s, acc_nat=0.59, acc_rob=0.333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 [0/383] | loss: 1.7724 (avg: 1.7724) | acc: 0.3750 (avg: 0.3750) |\n",
      "Epoch 32 [100/383] | loss: 1.5053 (avg: 1.6123) | acc: 0.5078 (avg: 0.4380) |\n",
      "Epoch 32 [200/383] | loss: 1.5999 (avg: 1.6125) | acc: 0.4531 (avg: 0.4363) |\n",
      "Epoch 32 [300/383] | loss: 1.7378 (avg: 1.6060) | acc: 0.3828 (avg: 0.4381) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:14<00:00,  5.13it/s, acc_nat=0.656, acc_rob=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 [0/383] | loss: 1.6464 (avg: 1.6464) | acc: 0.3984 (avg: 0.3984) |\n",
      "Epoch 33 [100/383] | loss: 1.5630 (avg: 1.5810) | acc: 0.5156 (avg: 0.4483) |\n",
      "Epoch 33 [200/383] | loss: 1.7061 (avg: 1.5977) | acc: 0.3906 (avg: 0.4424) |\n",
      "Epoch 33 [300/383] | loss: 1.6200 (avg: 1.6007) | acc: 0.4922 (avg: 0.4404) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:22<00:00,  4.94it/s, acc_nat=0.637, acc_rob=0.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 [0/383] | loss: 1.7648 (avg: 1.7648) | acc: 0.3828 (avg: 0.3828) |\n",
      "Epoch 34 [100/383] | loss: 1.5642 (avg: 1.5936) | acc: 0.4531 (avg: 0.4345) |\n",
      "Epoch 34 [200/383] | loss: 1.4669 (avg: 1.5946) | acc: 0.5469 (avg: 0.4390) |\n",
      "Epoch 34 [300/383] | loss: 1.8151 (avg: 1.6002) | acc: 0.2969 (avg: 0.4378) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:19<00:00,  5.01it/s, acc_nat=0.63, acc_rob=0.416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 [0/383] | loss: 1.6968 (avg: 1.6968) | acc: 0.3906 (avg: 0.3906) |\n",
      "Epoch 35 [100/383] | loss: 1.4377 (avg: 1.5874) | acc: 0.5078 (avg: 0.4411) |\n",
      "Epoch 35 [200/383] | loss: 1.5733 (avg: 1.5880) | acc: 0.4922 (avg: 0.4415) |\n",
      "Epoch 35 [300/383] | loss: 1.4914 (avg: 1.5942) | acc: 0.5078 (avg: 0.4416) |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[eval] 1000/1000: 100%|██████████| 1000/1000 [03:18<00:00,  5.05it/s, acc_nat=0.607, acc_rob=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 [0/383] | loss: 1.6058 (avg: 1.6058) | acc: 0.5000 (avg: 0.5000) |\n",
      "Epoch 36 [100/383] | loss: 1.6855 (avg: 1.6058) | acc: 0.4062 (avg: 0.4397) |\n",
      "Epoch 36 [200/383] | loss: 1.4447 (avg: 1.5928) | acc: 0.4844 (avg: 0.4485) |\n",
      "Epoch 36 [300/383] | loss: 1.7280 (avg: 1.6073) | acc: 0.3750 (avg: 0.4419) |\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = gpu\n",
    "os.makedirs(checkpoint, exist_ok=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()])\n",
    "train_dataset, _ = get_dataloader(dataset, batch_size)\n",
    "num_samples = len(train_dataset)\n",
    "num_samples_for_train = int(num_samples * 0.98)\n",
    "num_samples_for_valid = num_samples - num_samples_for_train\n",
    "train_set, valid_set = random_split(train_dataset, [num_samples_for_train, num_samples_for_valid])\n",
    "train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "valid_dataloader = DataLoader(valid_set, batch_size=1, shuffle=True, drop_last=False)\n",
    "\n",
    "model = nn.DataParallel(get_network(model_type, num_classes).cuda())\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = [75, 90]\n",
    "adjust_learning_rate = lr_scheduler.MultiStepLR(optimizer, scheduler, gamma=0.1)\n",
    "best_acc_nat, best_acc_rob = 0, 0\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    training(epoch, model, train_dataloader, optimizer, num_classes, tau, epsilon, alpha, num_repeats)\n",
    "    test_acc_nat, test_acc_rob = evaluation(epoch, model, valid_dataloader, alpha, epsilon, num_repeats)\n",
    "\n",
    "    is_best = best_acc_nat < test_acc_nat and best_acc_rob < test_acc_rob\n",
    "    best_acc_nat = max(best_acc_nat, test_acc_nat)\n",
    "    best_acc_rob = max(best_acc_rob, test_acc_rob)\n",
    "    save_checkpoint = {'state_dict': model.state_dict(),\n",
    "                       'best_acc_nat': best_acc_nat,\n",
    "                       'best_acc_rob': best_acc_rob,\n",
    "                       'optimizer': optimizer.state_dict(),\n",
    "                       'model_type': model_type,\n",
    "                       'dataset': dataset}\n",
    "    torch.save(save_checkpoint, os.path.join(checkpoint, 'model'))\n",
    "    if is_best:\n",
    "        torch.save(save_checkpoint, os.path.join(checkpoint, 'best_model'))\n",
    "    adjust_learning_rate.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67273057-ddb6-4294-b7ae-3aa932ab0cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f947e7ac-aa8a-4144-9e3a-bf7eb3e079a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
