training:
    # training setting
    dataset: 'cifar10'
    model_type: 'wrn34-10'
    total_epochs: 200
    batch_size: 128
    lr: 0.1
    momentum: 0.9
    weight_decay: 0.0002
    scheduler:
        - 100
        - 150
    num_classes: 10
    lower: 0
    upper: 1
    
    alpha: 2
    epsilon: 8
    num_repeats: 10
    tau: None
    lam: None
    lambda_av:
        - 1.0
        - 0.1
    gamma: 2
    beta: None
    pm_type: None
    warm_up: None
    xi: None
    wc: None
    wp: None
    lr_pc: None
    lr_center: None
    
    
