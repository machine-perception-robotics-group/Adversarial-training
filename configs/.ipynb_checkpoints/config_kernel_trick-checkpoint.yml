training_mnist_rbf-cnn:
    # training setting
    dataset: 'mnist'
    model_type: 'rbf_cnn'
    optim_type: 'adam'
    total_epochs: 100
    batch_size: 128
    lr: 0.001
    momentum: None
    weight_decay: None
    scheduler:
        - None
        - None
    num_classes: 10
    lower: 0
    upper: 1
    
    alpha: 20
    epsilon: 80
    num_repeats: 10
    tau: None
    lam: None
    lambda_av:
        - None
        - None
    gamma: None
    beta: None
    pm_type: None
    warm_up: None
    xi: None
    wc: None
    wp: None
    lr_pc: None
    lr_center: None
    
    
